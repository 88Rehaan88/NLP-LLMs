{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K7aMjbnO4MKx"
   },
   "source": [
    "# Word in Context (WiC) Classification Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VyuSXTwldWj7"
   },
   "source": [
    "**Please pay attention to these notes:**\n",
    "<br><br>\n",
    "\n",
    "- The coding parts you need to implement are denoted by:\n",
    "```\n",
    "    #################################\n",
    "    ## PUT YOU IMPLEMENTATION HERE ##\n",
    "    #################################\n",
    "```\n",
    "\n",
    "- You must run this notebook on Google Colab platform, it depends on Google Colab VM for some of the depencecies. <b><font color='red'> You must also use the GPU runtime for faster training of the model. </font></b>\n",
    "- <b><font color='red'>When you are ready to submit, please follow the instructions at the end of this notebook.</font></b>\n",
    "\n",
    "<br>\n",
    "\n",
    "--------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WZpsLISmd4e_"
   },
   "source": [
    "In this assignment, you will implement a classifier that determines whether a word has the same meaning in two different sentences. You'll be using the WiC (Word in Context) dataset and BERT embeddings to solve this task.\n",
    "\n",
    "First lets install the requirements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MJbQ6SHZ499b",
    "outputId": "93b109b4-08c4-4726-b33f-d8981fb8ab55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#importing clear_output() function from notebook utilities\n",
    "from IPython.display import clear_output\n",
    "\n",
    "!pip install datasets\n",
    "\n",
    "clear_output()\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UJTU-H_w4Nzy"
   },
   "source": [
    "## Dataset Description\n",
    "\n",
    "The WiC dataset provides pairs of sentences where a target word appears in both sentences. Your task is to determine whether the word is used with the same sense (meaning) in both sentences. For example:\n",
    "\n",
    "```\n",
    "Sentence 1: \"The house has a nice room.\"\n",
    "Sentence 2: \"There's not enough room for everyone.\"\n",
    "Target word: \"room\"\n",
    "Label: 0 (different meaning)\n",
    "```\n",
    "\n",
    "Each example in the dataset contains:\n",
    "- `sentence1`: First sentence\n",
    "- `sentence2`: Second sentence\n",
    "- `word`: The target word\n",
    "- `start1`  , `end1`: Character positions of the target word in sentence1\n",
    "- `start2`  , `end2`: Character positions of the target word in sentence2\n",
    "- `label`: 1 if the word has the same meaning in both sentences, 0 otherwise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DBVXQBC94J3_",
    "outputId": "a6ab03b1-a6e0-428d-980d-8a86e610c1d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset blueprint is: \n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['word', 'sentence1', 'sentence2', 'start1', 'start2', 'end1', 'end2', 'idx', 'label'],\n",
      "        num_rows: 5428\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['word', 'sentence1', 'sentence2', 'start1', 'start2', 'end1', 'end2', 'idx', 'label'],\n",
      "        num_rows: 638\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['word', 'sentence1', 'sentence2', 'start1', 'start2', 'end1', 'end2', 'idx', 'label'],\n",
      "        num_rows: 1400\n",
      "    })\n",
      "})\n",
      "============\n",
      "The first example of the train partition is: \n",
      "{'end1': 14,\n",
      " 'end2': 13,\n",
      " 'idx': 0,\n",
      " 'label': 0,\n",
      " 'sentence1': 'You must carry your camping gear .',\n",
      " 'sentence2': 'Sound carries well over water .',\n",
      " 'start1': 9,\n",
      " 'start2': 6,\n",
      " 'word': 'carry'}\n"
     ]
    }
   ],
   "source": [
    "# ==================================================================================\n",
    "#                    COPY THIS CELL INTO THE ASSIGNMENT NOTEBOOK                   #\n",
    "# ==================================================================================\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "# we download the files of the full dataset from here\n",
    "!pip install gdown\n",
    "!gdown --folder https://drive.google.com/drive/folders/1ZFz8-p40Ywoe8oBHb6H8ihO-boQqiq6_ -O /content/\n",
    "\n",
    "!pip install datasets\n",
    "\n",
    "# Lets take a look!\n",
    "\n",
    "from datasets import load_dataset\n",
    "from pprint import pprint\n",
    "\n",
    "# Load dataset\n",
    "\n",
    "####### WARNING! The Hugging Face version of the dataset does not include the test labels.\n",
    "####### However, you can obtain the full dataset by running the following script.\n",
    "####### Be sure to execute the previous cell first.\n",
    "\n",
    "dataset = load_dataset('./WiC/wic_loader.py',\n",
    "                        data_dir='./WiC',\n",
    "                        trust_remote_code=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Clear the output\n",
    "clear_output()\n",
    "\n",
    "print('The dataset blueprint is: ')\n",
    "print(dataset)\n",
    "print(\"============\")\n",
    "print('The first example of the train partition is: ')\n",
    "pprint(dataset['train'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-yziQFgwk9Oe"
   },
   "source": [
    "## How to approach the problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wKs45-o0laeN"
   },
   "source": [
    "To address this problem, we need a vector representation (embedding) of the target word in each of the two sentences. To achieve this, we first pass each sentence through the BERT model separately to obtain token embeddings. Next, we identify the sub-tokens corresponding to the target word in each sentence and compute their average embedding to represent the target word. Finally, we concatenate the two resulting vectors and feed them into a classifier, which determines whether the words share the same meaning based on these embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZAuwVW-OJnfo"
   },
   "source": [
    "In order to identify the sub-tokens corresponding to the target word, you should implement the `find_target_token_indices` function (similar to what we had in the class), which takes three inputs:\n",
    "\n",
    "- `start_idx`: The starting character index of the target word.\n",
    "- `end_idx`: The ending character index of the target word.\n",
    "- `offset_mapping`: A tensor containing character spans for each token in a tokenized sentence.\n",
    "\n",
    "The function should return a binary mask indicating which tokens correspond to the target word. To achieve this, iterate through offset_mapping and check if each token’s character span overlaps with the target word’s span (start_idx to end_idx). If there is an overlap, mark that token’s index in the mask as 1; otherwise, keep it 0. Finally, return the binary mask.\n",
    "\n",
    "\n",
    "Here is an example usage:\n",
    "\n",
    "```python\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "    \n",
    "    sentence = \"working with tokenizer is fun!.\"\n",
    "    target_word = \"tokenizer\"\n",
    "    start_idx = sentence.index(target_word)  # = 13\n",
    "    end_idx = start_idx + len(target_word) # = 22\n",
    "    \n",
    "    encoding = tokenizer(sentence, return_offsets_mapping=True, return_tensors=\"pt\")\n",
    "    offset_mapping = encoding[\"offset_mapping\"][0] # get the first item to remove the tokenizer's batching\n",
    "    input_ids = encoding[\"input_ids\"][0] # get the first item to remove the tokenizer's batching\n",
    "\n",
    "    mask = find_target_token_indices(start_idx, end_idx, offset_mapping)\n",
    "\n",
    "    print((tokenizer.convert_ids_to_tokens(input_ids)))\n",
    "   # >>> ['[CLS]', 'working', 'with', 'token', '##izer', 'is', 'fun', '!', '[SEP]']\n",
    "\n",
    "    print(mask)\n",
    "    # >>> tensor([0., 0., 0., 1., 1., 0., 0., 0., 0.])\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VutM2H7FDktO"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def find_target_token_indices(start_idx, end_idx, offset_mapping):\n",
    "    \"\"\"\n",
    "    Find token indices for a specific target word using offset mapping.\n",
    "\n",
    "    Args:\n",
    "        start_idx (int): Character start index of target word\n",
    "        end_idx (int): Character end index of target word\n",
    "        offset_mapping (torch.Tensor): Offset mapping from tokenization of the sentence\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Binary mask for target word tokens\n",
    "    \"\"\"\n",
    "    # Initialize a mask of zeros with the same length as offset_mapping\n",
    "    mask = torch.zeros(offset_mapping.shape[0], dtype=torch.float)\n",
    "\n",
    "    # Iterate through token offsets to find matching tokens\n",
    "    for i in range(offset_mapping.shape[0]):\n",
    "        token_start, token_end = offset_mapping[i].tolist()  # Convert tensor to list for indexing\n",
    "\n",
    "        # Check which tokens overlap with the target word\n",
    "        if (token_start < end_idx) and (token_end > start_idx):\n",
    "            mask[i] = 1.0\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KBsg6wMwHOiM"
   },
   "source": [
    "Test you implementation!\n",
    "\n",
    "Note: In this test, we remove the tokenizer's batching behavior when extracting `input_ids` and `offset_mapping` by selecting the first item (index `0`). Otherwise, the output would have two dimensions, with the first dimension that represents the batch always having a single item (length of 1), which is redundant since we only process a single sentence at a time (i.e., a batch size of one)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266,
     "referenced_widgets": [
      "0e67c11c88114305a92e751915f0874a",
      "d5080e58d85e48f990418346ab682647",
      "37d4a9723c1e4082806644019606edf1",
      "1a90f388cc204baa9b1d70744d866251",
      "2582199e81c34d0bb9b01e67acd9a227",
      "2bc9033d0c1e466f98f671e1c5241206",
      "3240f2633b664076801a7b4328c5aab9",
      "ede26fe1552a4433913e75e50acb7844",
      "b1c323fd64ae4744ab5743c5c473f259",
      "b60c939fa05d42c4af016cf596f1e80b",
      "68421f01758644d98f4025ae3a20a532",
      "7612951613684af885c00485caa4510f",
      "be29a237a2d146adad658ca1bd347dd8",
      "ae39644865bc4a6288c6876c8ea77ffb",
      "2a8f16110e3d48199e58857d5cdcff61",
      "41d33412c681498dbca82de24b21655c",
      "060c905f08004cc0b6b41459d68b1c32",
      "c214ccb62cb844faa7463dc7aa7311b3",
      "13c7cb6e9ddf42c296aa9adfdc308eeb",
      "1fa730c110cc4e2eaacc28a8e9efabf7",
      "712f42593f5c4aeb9f857e0d480b44be",
      "ddad1150efbc4d10a500bcae92efacae",
      "e1c8517e25714281921b5a1ad8fb6e9c",
      "eb7afc94619648d8b019f8d5e530c5e5",
      "aeac0224d04e42769497c5690471314f",
      "685fa9d107f64110b9a0d90b9880066b",
      "58475780b89644e3a42946c6cc193c1d",
      "501a7db007e84e8aa317eedc2f770bf4",
      "94bd2d0656074542b3438c05c9e1e060",
      "8bb04f18590f47b880988632b3cb5ac3",
      "0e8bf5c473f645ac8059762f8c6fdbf4",
      "9350d228b686468d8fb43f3bdfba9aa3",
      "116a4d9682634229b55e82e3ed9044a7",
      "5cc8f19f5206461fa3387232ffc87e47",
      "dadfcb37b4494b19a8dd885ba5bfa0dc",
      "1c503a1817584c329f7ff02db37ca31a",
      "3c0996958c5d457f90460172ced7cbf0",
      "2ff00002daa145efadcd5d40e485dbb4",
      "9c9039d3b26d4061863dd2af1cc63f42",
      "1b51d3fbe4e544cfa4bd68985dbaeeab",
      "8d276eda27bb4c7e9ecfcbaebe8d5d9e",
      "957af2dce6ef4fdca0094ab8f49e5d01",
      "193a1cd8b67c419da907a09f404ded44",
      "b0ae235594e4420082e6cc17d11fbcdd"
     ]
    },
    "id": "6m2T0ehnDyoU",
    "outputId": "f9dd2b77-7832-4f35-c8b0-02186a845f2b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e67c11c88114305a92e751915f0874a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7612951613684af885c00485caa4510f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1c8517e25714281921b5a1ad8fb6e9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cc8f19f5206461fa3387232ffc87e47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple test passed!\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Loading the Tokenizer:\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Test case: Basic word detection\n",
    "sentence = \"Working with tokenizer is fun!\"\n",
    "target_word = \"tokenizer\"\n",
    "start_idx = sentence.index(target_word)\n",
    "end_idx = start_idx + len(target_word)\n",
    "encoding = tokenizer(sentence, return_offsets_mapping=True, return_tensors=\"pt\")\n",
    "offset_mapping = encoding[\"offset_mapping\"][0] # get the first item to remove the tokenizer's batching\n",
    "input_ids = encoding[\"input_ids\"][0] # get the first item to remove the tokenizer's batching\n",
    "\n",
    "mask = find_target_token_indices(start_idx, end_idx, offset_mapping)\n",
    "\n",
    "assert mask.shape == input_ids.shape, \"Mask should have the same shape as input_ids\"\n",
    "assert mask.sum().item() > 0, \"Target word indices should be masked\"\n",
    "assert (tokenizer.decode(input_ids[mask==1])) == \"tokenizer\", \"Wrong word is masked!\"\n",
    "\n",
    "print(\"Simple test passed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0naCUZcYLYHB"
   },
   "source": [
    "## WiCDataset class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ZXnPLpwwY9V"
   },
   "source": [
    "The WiCDataset class implements a PyTorch Dataset for the Word-in-Context (WiC) task. It processes pairs of sentences where a target word appears in both, preparing the data for a model to determine if the word has the same meaning in both contexts.\n",
    "The inputs are:\n",
    "\n",
    "Inputs:\n",
    "- `dataset` containing sentence pairs, target word indices, and labels;\n",
    "- `tokenizer` : an instance of bert tokenizer;\n",
    "- `max_length` : the max length parameter that we pass to the tokenizer when encoding a sentence.\n",
    "\n",
    "When the `__getitem__` method is called, you should extract the sentence pairs, word indices, and labels for the dataset item at index `idx`. Then, tokenize both sentences with padding and truncation. Next, create target masks to highlight the word positions using the `find_target_token_indices` function you implemented earlier.  \n",
    "\n",
    "Your output should be a dictionary containing the tokenized inputs, attention masks, target masks, the item label, and the target word.\n",
    "\n",
    "Example usage:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "dataset = dataset = load_dataset(\"super_glue\", \"wic\",\n",
    "                       trust_remote_code=True)\n",
    "wic_dataset = WiCDataset(dataset[\"train\"], tokenizer)\n",
    "\n",
    "# Get first instance\n",
    "sample = wic_dataset[0]\n",
    "\n",
    "# Print original sentences\n",
    "print(\"Sentence 1:\", dataset[\"train\"][\"sentence1\"][0])\n",
    "print(\"Sentence 2:\", dataset[\"train\"][\"sentence2\"][0])\n",
    "print(\"Target word:\", sample[\"word\"])\n",
    "print(\"Label:\", sample[\"label\"])\n",
    "\n",
    "# Print tokenized output\n",
    "print(\"\\nTokenized sentence 1:\",\n",
    "      tokenizer.convert_ids_to_tokens(sample[\"input_ids1\"]))\n",
    "\n",
    "# Show target word position\n",
    "print(\"\\nTarget mask 1:\", sample[\"target_mask1\"])\n",
    "print(\"Target mask 2:\", sample[\"target_mask2\"])\n",
    "\n",
    "# Check attention masks (1 for tokens, 0 for padding)\n",
    "print(\"\\nAttention mask 1:\", sample[\"attention_mask1\"])\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cyQFUaVDkl4b"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "class WiCDataset(Dataset):\n",
    "    def __init__(self, dataset, tokenizer, max_length=128):\n",
    "        \"\"\"\n",
    "        Initializes the WiC dataset.\n",
    "\n",
    "        Args:\n",
    "            dataset: Dataset containing sentence pairs, target word indices, and labels\n",
    "            tokenizer: BERT Tokenizer\n",
    "            max_length: Maximum token length for tokenization\n",
    "        \"\"\"\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)  # Return the size of the dataset\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Retrieves and processes a single data instance from the dataset.\n",
    "\n",
    "        Args:\n",
    "            idx: Index of the data instance\n",
    "\n",
    "        Returns:\n",
    "            A dictionary containing tokenized input, target masks, and label for the instance.\n",
    "        \"\"\"\n",
    "        # Extracting sentence pair, word, label, start and end indices\n",
    "        item = self.dataset[idx]\n",
    "        sentence1 = item['sentence1']\n",
    "        sentence2 = item['sentence2']\n",
    "        word = item['word']\n",
    "        label = item['label']\n",
    "        start1 = item['start1']\n",
    "        end1 = item['end1']\n",
    "        start2 = item['start2']\n",
    "        end2 = item['end2']\n",
    "\n",
    "        # Tokenize sentence1\n",
    "        encoding1 = self.tokenizer(\n",
    "            sentence1,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',      # Pad the sentences to the max length\n",
    "            truncation=True,           # Truncate if necessary\n",
    "            return_offsets_mapping=True,\n",
    "            return_tensors='pt'        # Return as PyTorch tensors\n",
    "        )\n",
    "\n",
    "        # Removing batch dimensions\n",
    "        input_ids1 = encoding1['input_ids'].squeeze(0)\n",
    "        attention_mask1 = encoding1['attention_mask'].squeeze(0)\n",
    "        offset_mapping1 = encoding1['offset_mapping'].squeeze(0)\n",
    "        target_mask1 = find_target_token_indices(start1, end1, offset_mapping1)  # Generate target mask for sentence1\n",
    "\n",
    "        # Tokenize sentence2\n",
    "        encoding2 = self.tokenizer(\n",
    "            sentence2,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',       # Pad the sentences to the max length\n",
    "            truncation=True,            # Truncate if necessary\n",
    "            return_offsets_mapping=True,\n",
    "            return_tensors='pt'         # Return as PyTorch tensors\n",
    "        )\n",
    "\n",
    "        # Removing batch dimensions\n",
    "        input_ids2 = encoding2['input_ids'].squeeze(0)\n",
    "        attention_mask2 = encoding2['attention_mask'].squeeze(0)\n",
    "        offset_mapping2 = encoding2['offset_mapping'].squeeze(0)\n",
    "        target_mask2 = find_target_token_indices(start2, end2, offset_mapping2)  # Generate target mask for sentence2\n",
    "\n",
    "        # Return the processed data as a dictionary\n",
    "        return {\n",
    "            'input_ids1': input_ids1,\n",
    "            'attention_mask1': attention_mask1,\n",
    "            'input_ids2': input_ids2,\n",
    "            'attention_mask2': attention_mask2,\n",
    "            'target_mask1': target_mask1,\n",
    "            'target_mask2': target_mask2,\n",
    "            'label': torch.tensor(label, dtype=torch.long),  # Convert label to tensor\n",
    "            'word': word     # Returns the target word\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N6xrkI6fktCr"
   },
   "source": [
    "Test your WiCDataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d1I1EBr8NgZh",
    "outputId": "7ce70726-1555-4999-e90b-df7912b11ca3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids1': tensor([[  101,  2017,  2442,  4287,  2115, 13215,  6718,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0],\n",
      "        [  101,  7696,  2442,  2175,  2083,  8041,  6833,  1012,   102,     0,\n",
      "             0,     0,     0,     0,     0],\n",
      "        [  101,  3338,  2019,  4862,  5638,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0],\n",
      "        [  101,  2002,  5078,  1037, 23407, 16195,  2007,  1037,  3384,  2452,\n",
      "          1012,   102,     0,     0,     0],\n",
      "        [  101,  1996,  2914,  1997,  2189,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0]]), 'attention_mask1': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]]), 'input_ids2': tensor([[  101,  2614,  7883,  2092,  2058,  2300,  1012,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0],\n",
      "        [  101,  2079,  2017,  2228,  1996, 10682,  2097,  2175,  2083,  1996,\n",
      "          2341,  1029,   102,     0,     0],\n",
      "        [  101,  1996, 17264,  2099,  3631,  1996, 11661, 15665,  2046, 27396,\n",
      "          2015,  1998,  8378,  2005,   102],\n",
      "        [  101, 13734,  3561,  1996, 13844,  2368, 10268,  2007,  6861,  1012,\n",
      "           102,     0,     0,     0,     0],\n",
      "        [  101,  1996,  2413,  2914,  1012,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0]]), 'attention_mask2': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'target_mask1': tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), 'target_mask2': tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), 'label': tensor([0, 0, 0, 1, 0]), 'word': ['carry', 'go', 'break', 'cup', 'academy']}\n",
      "Simple test passed!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# A simple dataset to test\n",
    "dataset_sample = dataset['train'].select(range(5))  # Select first 5 rows correctly\n",
    "\n",
    "# Simple tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Create DataLoader\n",
    "dataset_instance = WiCDataset(dataset_sample, tokenizer, max_length=15)\n",
    "dataloader = DataLoader(dataset_instance, batch_size=5, shuffle=False)\n",
    "\n",
    "# Testing the first batch\n",
    "batch = next(iter(dataloader))\n",
    "print(batch)\n",
    "\n",
    "assert tokenizer.convert_ids_to_tokens(batch['input_ids1'][batch['target_mask1']==1]) == batch['word'], 'Wrong words masked!'\n",
    "print('Simple test passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bX6U-0zmSlmX"
   },
   "source": [
    "## WiCClassifier torch module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f_GE0XSKnH5-"
   },
   "source": [
    "To build a WiC classifier, create a PyTorch model that inherits from nn.Module. Your model should use a pre-trained BERT model to extract contextual embeddings and include a classifier for binary classification. The classifier should consist of a nn.Linear layer followed by a nn.ReLU activation. The input size of the linear layer should be 2 * bert_hidden_size (which is 768 for BERT, resulting in 1536), and the output size should be 2, equal to the number of our classes. The input size is doubled because the model concatenates two vectors of size 768—as we see later in `forward` method, each representing the target word embedding from one of the two sentences—before passing them to the classifier.\n",
    "\n",
    "In the `__init__` method, store the BERT model as `self.bert`, and define the linear classifier with the appropriate input and output sizes and the relu activation function. After the linear layer, apply `nn.ReLU()` to introduce non-linearity and improve the model’s ability to capture complex patterns. You can stack different torch modules on top using `nn.Sequential` ([look at the PyTorch documentation for more details](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html)). This setup ensures that your model can effectively distinguish between the two classes.\n",
    "\n",
    "The `forward` method should take six inputs: two sets of input IDs and attention masks, along with two target masks. First, pass these inputs through BERT to obtain the contextual embeddings for both sentences. Then, compute the target word representations using masked averaging: multiply the embeddings by the target mask to zero out the embeddings of subwords that do not belong to the target word, sum the remaining embeddings, and divide by the number of subword tokens of the target word. Finally, concatenate these average-pulled target word representations and pass the resulting vector through the classifier you initialized earlier to generate the prediction.\n",
    "\n",
    "Note: At some point, you should be using the `unsqueeze()` method of torch tensors to ensure correct broadcasting (hint: when applying target masks to the extracted embeddings). Also, make sure that all operations maintain the batch dimension so that your model works correctly during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bdz1of4HmGDt"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class WiCClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, bert_model):\n",
    "        \"\"\"\n",
    "        Initialize the WiCClassifier model.\n",
    "\n",
    "        Args:\n",
    "            bert_model (nn.Module): Pre-trained BERT model for contextual embeddings\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.bert = bert_model\n",
    "\n",
    "        # Defining a Classifier : Linear layer followed by ReLU activation\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(2 * 768, 2), # Input size: 2 * BERT hidden size (768), Output size: 2 (for binary classification)\n",
    "            nn.ReLU()              # ReLU activation to introduce non-linearity to the model\n",
    "        )\n",
    "\n",
    "        \"\"\"\n",
    "        Shape of all the input tensors is > [batch_size, max_sequence_length]\n",
    "\n",
    "        Args:\n",
    "            input_ids1 (torch.Tensor): Tokenized input IDs for first sentence\n",
    "            attention_mask1 (torch.Tensor): Attention mask for first sentence\n",
    "            input_ids2 (torch.Tensor): Tokenized input IDs for second sentence\n",
    "            attention_mask2 (torch.Tensor): Attention mask for second sentence\n",
    "            target_mask1 (torch.Tensor): Binary mask highlighting target word tokens in first sentence\n",
    "            target_mask2 (torch.Tensor): Binary mask highlighting target word tokens in second sentence\n",
    "\n",
    "        Output:\n",
    "            classification_logits (torch.Tensor): Logits for binary classification > Shape: [batch_size, 2]\n",
    "\n",
    "        Workflow:\n",
    "        1. Extract contextual embeddings for both sentences using BERT\n",
    "        2. Compute target word representations by masked averaging\n",
    "        3. Concatenate target word representations\n",
    "        4. Classify using a linear layer\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, input_ids1, attention_mask1, input_ids2, attention_mask2, target_mask1, target_mask2):\n",
    "        # Get embeddings for both sentences\n",
    "        outputs1 = self.bert(input_ids1, attention_mask=attention_mask1)\n",
    "        embeddings1 = outputs1.last_hidden_state   # Extract embeddings from the last hidden layer\n",
    "        outputs2 = self.bert(input_ids2, attention_mask=attention_mask2)\n",
    "        embeddings2 = outputs2.last_hidden_state   # Extract embeddings from the last hidden layer\n",
    "\n",
    "        # Compute target word embeddings dor both sentences using masked average\n",
    "\n",
    "        # Mask the embeddings by target word positions and sum the masked tokens\n",
    "        target_mask1 = target_mask1.unsqueeze(-1) # Add an extra dimension for broadcasting\n",
    "        masked_embeddings1 = embeddings1 * target_mask1  # Apply target mask to embeddings\n",
    "        summed_embeddings1 = torch.sum(masked_embeddings1, dim=1) # Sum embeddings along sequence dimension\n",
    "        sum_mask1 = torch.sum(target_mask1.squeeze(-1), dim=1, keepdim=True)  #Count the number of subword tokens\n",
    "        avg_embeddings1 = summed_embeddings1 / sum_mask1.clamp(min=1e-9)      # Compute average by dividing by token count\n",
    "\n",
    "        target_mask2 = target_mask2.unsqueeze(-1) # Add an extra dimension for broadcasting\n",
    "        masked_embeddings2 = embeddings2 * target_mask2  # Apply target mask to embeddings\n",
    "        summed_embeddings2 = torch.sum(masked_embeddings2, dim=1)  # Sum embeddings along sequence dimension\n",
    "        sum_mask2 = torch.sum(target_mask2.squeeze(-1), dim=1, keepdim=True)  # Count the number of subword tokens\n",
    "        avg_embeddings2 = summed_embeddings2 / sum_mask2.clamp(min=1e-9) # Compute avg by dividing by token count\n",
    "\n",
    "        # Concatenate thee target word representations from both sentences\n",
    "        combined = torch.cat([avg_embeddings1, avg_embeddings2], dim=1)\n",
    "\n",
    "         # Pass the concatenated vector through the classifier to get logits\n",
    "        logits = self.classifier(combined)  # Apply the linear layer with ReLU activation\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JfWlR1o-bngm"
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i9b6qzQ8bpVQ"
   },
   "source": [
    "You can train your model using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 257,
     "referenced_widgets": [
      "df1d4c0014704a8d8a259364fca71e60",
      "1040cb186f9f4a168e0804ac84927919",
      "12479acb03b54381a86059a1b5c15768",
      "66460bc5a9d346298b3d15b0b74bd4d4",
      "ac78a12e2f5b4fbeae698071b09f00cd",
      "5e60cad65caa4cecb781fc53433e5505",
      "da6c8bd1caf44a068d004af30f937ace",
      "d541839118c54eb5985d48a8ddf6504c",
      "217a9818313c459a88a85bdd996daa70",
      "f3974d267f8f4a059eed443434eaee2b",
      "22c4fe11e24549fd85c6e4826cf51913"
     ]
    },
    "id": "I0DuBulPrjna",
    "outputId": "731fcdd2-a5a2-4204-c6ab-220f0daf6e5e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df1d4c0014704a8d8a259364fca71e60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170/170 [03:20<00:00,  1.18s/it, Loss=0.575]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 done!\n",
      "Average training loss: 0.6705\n",
      "Validation accuracy: 0.5627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170/170 [03:25<00:00,  1.21s/it, Loss=0.784]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 done!\n",
      "Average training loss: 0.5434\n",
      "Validation accuracy: 0.5690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170/170 [03:25<00:00,  1.21s/it, Loss=0.42]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 done!\n",
      "Average training loss: 0.4069\n",
      "Validation accuracy: 0.5768\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel\n",
    "\n",
    "num_epochs = 3\n",
    "learning_rate = 2e-5\n",
    "max_length=128\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "train_dataset = WiCDataset(dataset['train'], tokenizer, max_length)\n",
    "val_dataset = WiCDataset(dataset['validation'], tokenizer, max_length)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "\n",
    "\n",
    "bert_model = AutoModel.from_pretrained('bert-base-uncased')\n",
    "model = WiCClassifier(bert_model)\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    progress_bar = tqdm(train_loader)\n",
    "    for batch in progress_bar:\n",
    "        input_ids1 = batch['input_ids1'].to(device)\n",
    "        input_ids2 = batch['input_ids2'].to(device)\n",
    "        attention_mask1 = batch['attention_mask1'].to(device)\n",
    "        attention_mask2 = batch['attention_mask2'].to(device)\n",
    "        target_mask1 = batch['target_mask1'].to(device)\n",
    "        target_mask2 = batch['target_mask2'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids1,\n",
    "                        attention_mask1,\n",
    "                        input_ids2,\n",
    "                        attention_mask2,\n",
    "                        target_mask1,\n",
    "                        target_mask2)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        progress_bar.set_postfix({f\"Loss\": loss.item()})\n",
    "\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "\n",
    "            input_ids1 = batch['input_ids1'].to(device)\n",
    "            input_ids2 = batch['input_ids2'].to(device)\n",
    "            attention_mask1 = batch['attention_mask1'].to(device)\n",
    "            attention_mask2 = batch['attention_mask2'].to(device)\n",
    "            target_mask1 = batch['target_mask1'].to(device)\n",
    "            target_mask2 = batch['target_mask2'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "\n",
    "\n",
    "            outputs = model(input_ids1, attention_mask1, input_ids2, attention_mask2, target_mask1, target_mask2)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_acc = correct / total\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} done!\")\n",
    "    print(f\"Average training loss: {total_loss/len(train_loader):.4f}\")\n",
    "    print(f\"Validation accuracy: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gQYQmgLEcJoj"
   },
   "source": [
    "The WiC dataset includes a test set, in addition to the train and validation sets. Write a code to evaluate your model on the test set of the WiC dataset and print out the accuracy, following a similar approach as we did in the training loop with the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VaHW0Q3Hcuyy",
    "outputId": "027351c3-74d8-4702-8e51-4ee20a53c90d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.5507\n"
     ]
    }
   ],
   "source": [
    "test_dataset = WiCDataset(dataset['test'], tokenizer, max_length)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16)\n",
    "\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        # Move batch tensors to the same device as the model\n",
    "        input_ids1 = batch['input_ids1'].to(device)\n",
    "        attention_mask1 = batch['attention_mask1'].to(device)\n",
    "        input_ids2 = batch['input_ids2'].to(device)\n",
    "        attention_mask2 = batch['attention_mask2'].to(device)\n",
    "        target_mask1 = batch['target_mask1'].to(device)\n",
    "        target_mask2 = batch['target_mask2'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        # Get model predictions:\n",
    "        outputs = model(input_ids1, attention_mask1, input_ids2, attention_mask2, target_mask1, target_mask2)\n",
    "\n",
    "        # Get predicted class\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        # Update correct count and total count\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Print Test accuracy\n",
    "print(f\"Test Accuracy: {correct/total:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "orlWgTiiutrr"
   },
   "source": [
    "## Improve your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ukIVLT7uw_I"
   },
   "source": [
    "This section is all yours! Try exploring a different approach to solving this task. You could experiment with modifying the classifier architecture—for example, adding more linear layers instead of using just one. Additionally, consider adjusting the training hyperparameters, such as increasing the number of training epochs, to improve performance.\n",
    "\n",
    "Go ahead and implement your new model and training loop. Your updated training loop should also record the loss at each iteration. Once training is complete, visualize the recorded training loss values by plotting them using a library like Matplotlib. You must also aim for a final test accuracy in the range of 65–70%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "RujlcaoPE6v0",
    "outputId": "4f94e9cc-5e42-4b9e-dac3-e99787c48e6b"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n",
      "Training with Config 1 (r=10, lora_alpha=16)\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 170/170 [02:32<00:00,  1.11it/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 done! Average training loss: 0.6744\n",
      "Validation accuracy for Config 1: 0.5972\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 170/170 [02:32<00:00,  1.12it/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 done! Average training loss: 0.6205\n",
      "Validation accuracy for Config 1: 0.6395\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 170/170 [02:32<00:00,  1.12it/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 done! Average training loss: 0.5826\n",
      "Validation accuracy for Config 1: 0.6254\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 170/170 [02:31<00:00,  1.12it/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 done! Average training loss: 0.5590\n",
      "Validation accuracy for Config 1: 0.6301\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 170/170 [02:31<00:00,  1.12it/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 done! Average training loss: 0.5527\n",
      "Validation accuracy for Config 1: 0.6254\n",
      "Training with Config 2 (r=12, lora_alpha=15)\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 170/170 [02:31<00:00,  1.12it/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 done! Average training loss: 0.6747\n",
      "Validation accuracy for Config 2: 0.5972\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 170/170 [02:31<00:00,  1.12it/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 done! Average training loss: 0.6162\n",
      "Validation accuracy for Config 2: 0.6223\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 170/170 [02:31<00:00,  1.12it/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 done! Average training loss: 0.5820\n",
      "Validation accuracy for Config 2: 0.6285\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 170/170 [02:31<00:00,  1.12it/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 done! Average training loss: 0.5624\n",
      "Validation accuracy for Config 2: 0.6332\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 170/170 [02:32<00:00,  1.12it/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 done! Average training loss: 0.5471\n",
      "Validation accuracy for Config 2: 0.6301\n",
      "Training with Config 3 (r=14, lora_alpha=14)\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 170/170 [02:32<00:00,  1.12it/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 done! Average training loss: 0.6820\n",
      "Validation accuracy for Config 3: 0.6301\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 170/170 [02:32<00:00,  1.12it/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 done! Average training loss: 0.6224\n",
      "Validation accuracy for Config 3: 0.6144\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 170/170 [02:32<00:00,  1.12it/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 done! Average training loss: 0.5825\n",
      "Validation accuracy for Config 3: 0.6379\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 170/170 [02:32<00:00,  1.12it/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 done! Average training loss: 0.5636\n",
      "Validation accuracy for Config 3: 0.6473\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 170/170 [02:32<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 done! Average training loss: 0.5527\n",
      "Validation accuracy for Config 3: 0.6426\n",
      "Best Validation Accuracy: 0.6473\n",
      "Best Configuration: Config 3 (r=14, lora_alpha=14)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkcAAAHHCAYAAAC1G/yyAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAciNJREFUeJzt3XdcE/cfBvAnCSTsLYhsxY2CoiJSR927tta6WtEOW0VFqXW0VbvUtlaLq67W8WvrxFHrrOJonSi4F6IyHCzZICu53x+UlAgqIHABnvfrlVfL5e7ySUxyTz73vTuJIAgCiIiIiAgAIBW7ACIiIiJtwnBEREREVATDEREREVERDEdERERERTAcERERERXBcERERERUBMMRERERUREMR0RERERFMBwRERERFcFwVMlGjx4NZ2fnci37xRdfQCKRVGxBNdCCBQtQv359yGQyeHh4iF1OrRYZGQmJRIL169eXedljx45BIpHg2LFjpZr/+++/R5MmTaBSqcr8WJUlPz8f06ZNg4ODA6RSKQYNGgQAkEgk+OKLL0St7WkqlQpubm6YO3eu2KVUKmdnZ4wePVrsMl7ay2xLRo8eDSMjo4otSEvk5eXBwcEBP/30U7H7Vq5cCUdHR+Tk5JR5vbU2HEkkklLdSvtFXdNUlw/TX3/9hWnTpsHHxwfr1q3DvHnzKvXxRo8erfH+0NHRgYODA4YNG4br169X2uNev34dX3zxBSIjI0s1f2GwlkqliImJKXZ/Wloa9PX1IZFIMGHChAqutvKlpaXhu+++w/Tp0yGVan6NZWdn48cff4SXlxdMTU2hp6eHRo0aYcKECQgPD6/UutauXYsFCxbgzTffxIYNGzBlypRKeZydO3eiV69eqFevHhQKBezt7fHmm2/i6tWrpV7Hpk2bEBMTU+n//rdu3cKUKVPQoUMH6OnpQSKRlOp9fOfOHfX858+fr9Qaqeps2bIFb7/9Nho2bAiJRIIuXbqUarm5c+dCIpHAzc1NY7quri4CAgIwd+5cZGdna9w3evRo5ObmYtWqVWWuU6fMS9QQv/76q8bf//vf/3Do0KFi05s2bfpSj7NmzZpy/7L9/PPPMWPGjJd6/JruyJEjkEql+OWXXyCXy6vkMRUKBX7++WcABZ2CO3fuYOXKlThw4ACuX7+OevXqVfhjXr9+HV9++SW6dOlSpl+PCoUCmzZtwrRp0zSm79ixo4IrrFpr165Ffn4+hg8frjE9MTERvXv3RmhoKPr3748RI0bAyMgIt27dwubNm7F69Wrk5uZWWl1HjhyBnZ0dfvzxR43pT548gY5OxX3dXrlyBebm5vD394eVlRViY2Oxdu1atGvXDqdPn4a7u/sL17FgwQIMGzYMpqamFVZXSU6fPo0lS5agWbNmaNq0KS5evFiq5aZMmQIdHZ1y/eon7bVixQqEhoaibdu2ePz4camWuX//PubNmwdDQ8MS7x8zZgxmzJiBjRs34t1331VP19PTg6+vLxYtWoSJEyeWaU9MrQ1Hb7/9tsbfZ86cwaFDh4pNf1pWVhYMDAxK/Ti6urrlqg8AdHR0KvQLtSaKj4+Hvr5+hQUjQRCQnZ0NfX39Z86jo6NT7H3Svn179O/fH3v37sUHH3xQIbVUhL59+5YYjjZu3Ih+/fph+/btIlX2ctatW4eBAwdCT09PY/ro0aNx4cIFBAUFYfDgwRr3ff311/jss88qta74+HiYmZkVm/50nS9r9uzZxaa9//77sLe3x4oVK7By5crnLn/hwgVcunQJCxcufOFjZWZmPnOjVBoDBw5ESkoKjI2N8cMPP5QqHB08eBAHDx7EtGnT8M0335T7sStadnY25HJ5sW4lld6vv/4KOzs7SKXSYl2gZ5k6dSrat28PpVKJxMTEYvebmZmhZ8+eWL9+vUY4AoC33noL33//PY4ePYquXbuWuk7+Cz9Hly5d4ObmhtDQUHTq1AkGBgb49NNPAQB//PEH+vXrp25rN2jQAF9//TWUSqXGOp7eT1w4JuOHH37A6tWr0aBBAygUCrRt2xbnzp3TWLakMUeFu0F27doFNzc3KBQKNG/eHAcOHChW/7Fjx9CmTRvo6emhQYMGWLVqVYWPY9q2bRs8PT2hr68PKysrvP3223jw4IHGPLGxsRgzZgzs7e2hUChga2uL1157TaO1fv78efTq1QtWVlbQ19eHi4tLsTf50yQSCdatW4fMzEz1bq7CsS75+fn4+uuv1a+vs7MzPv3002K/Qp2dndG/f38cPHgQbdq0gb6+frlasHXr1gWAYmE2JSUFkydPhoODAxQKBVxdXfHdd98V6yZu3rwZnp6eMDY2homJCVq0aIHFixcDANavX48hQ4YAAF599dUy7fIdMWIELl68iJs3b6qnxcbG4siRIxgxYkSJy8THx+O9996DjY0N9PT04O7ujg0bNhSbLyUlBaNHj4apqSnMzMzg6+uLlJSUEtd58+ZNvPnmm7CwsICenh7atGmD3bt3v7D+kty7dw+XL19G9+7dNaafPXsWe/fuxXvvvVcsGAEFXbQffvhBY9qRI0fQsWNHGBoawszMDK+99hpu3LihMU/hZyYiIgKjR4+GmZkZTE1NMWbMGGRlZQH473N99OhRXLt2rdi/UUljjir682ltbQ0DA4Nn/hsUtWvXLsjlcnTq1KnE53r9+nWMGDEC5ubmeOWVV8pVTyELCwsYGxuXev68vDz4+/vD398fDRo0eKnHfpa7d+9iyJAhsLCwgIGBAdq3b4+9e/dqzFM4Bm7z5s34/PPPYWdnBwMDA6SlpSEpKQlTp05FixYtYGRkBBMTE/Tp0weXLl0qcy2l3ZY8rei25Mcff4STkxP09fXRuXPnZ+5effDgAQYNGgQjIyPUqVMHU6dOLfY4P/zwAzp06ABLS0vo6+vD09MTQUFBZX5ez1I4Hq+0/v77bwQFBSEwMPC58/Xo0QMnTpxAUlKSxnRPT09YWFjgjz/+KFOdbEu8wOPHj9GnTx8MGzYMb7/9NmxsbAAUbLCMjIwQEBAAIyMjHDlyBLNnz0ZaWhoWLFjwwvVu3LgR6enp+PDDDyGRSPD999/jjTfewN27d1/YbTpx4gR27NiB8ePHw9jYGEuWLMHgwYMRHR0NS0tLAAW/DHv37g1bW1t8+eWXUCqV+Oqrr1CnTp2Xf1H+tX79eowZMwZt27bF/PnzERcXh8WLF+PkyZO4cOGC+hf04MGDce3aNUycOBHOzs6Ij4/HoUOHEB0drf67Z8+eqFOnDmbMmAEzMzNERka+cNfPr7/+itWrVyMkJES9m6tDhw4ACn5Fb9iwAW+++SY+/vhjnD17FvPnz8eNGzewc+dOjfXcunULw4cPx4cffogPPvgAjRs3fuFzL/z1olQqcffuXUyfPh2Wlpbo37+/ep6srCx07twZDx48wIcffghHR0ecOnUKM2fOxKNHj9Qf9kOHDmH48OHo1q0bvvvuOwDAjRs3cPLkSfj7+6NTp06YNGkSlixZgk8//VS9q7c0u3w7deoEe3t7bNy4EV999RWAgn3+RkZG6NevX7H5nzx5gi5duiAiIgITJkyAi4sLtm3bhtGjRyMlJQX+/v4ACjpsr732Gk6cOIGPPvoITZs2xc6dO+Hr61tsndeuXYOPjw/s7OwwY8YMGBoaYuvWrRg0aBC2b9+O119//YXPo6hTp04BAFq3bq0xvTBsvfPOO6Vaz+HDh9GnTx/Ur18fX3zxBZ48eYKlS5fCx8cHYWFhxXZfvvXWW3BxccH8+fMRFhaGn3/+GdbW1vjuu+9Qp04d/Prrr5g7dy4yMjIwf/58AM/+N6qoz2dKSgry8vIQGxuLwMBApKWloVu3bi9c7tSpU3Bzc3vmd82QIUPQsGFDzJs3D4IgAABycnKQnp5eqrqsrKxK/ySeEhgYiOTkZHz++eeVsvs3Li4OHTp0QFZWFiZNmgRLS0ts2LABAwcORFBQULH349dffw25XI6pU6ciJycHcrkc169fx65duzBkyBC4uLggLi4Oq1atQufOncu8a/1ltyX/+9//kJ6eDj8/P2RnZ2Px4sXo2rUrrly5ot5eAQXfVb169YKXlxd++OEHHD58GAsXLkSDBg0wbtw49XyLFy/GwIEDMXLkSOTm5mLz5s0YMmQI9uzZo/GdkZqairy8vBfWp6enV+7xq0qlEhMnTsT777+PFi1aPHdeT09PCIKAU6dOaXwPAwXfFSdPnizbgwskCIIg+Pn5CU+/HJ07dxYACCtXriw2f1ZWVrFpH374oWBgYCBkZ2erp/n6+gpOTk7qv+/duycAECwtLYWkpCT19D/++EMAIPz555/qaXPmzClWEwBBLpcLERER6mmXLl0SAAhLly5VTxswYIBgYGAgPHjwQD3t9u3bgo6OTrF1lsTX11cwNDR85v25ubmCtbW14ObmJjx58kQ9fc+ePQIAYfbs2YIgCEJycrIAQFiwYMEz17Vz504BgHDu3LkX1lWaOi9evCgAEN5//32N6VOnThUACEeOHFFPc3JyEgAIBw4cKPXjASh2s7OzE0JDQzXm/frrrwVDQ0MhPDxcY/qMGTMEmUwmREdHC4IgCP7+/oKJiYmQn5//zMfdtm2bAEA4evRoqeosfO8kJCQIU6dOFVxdXdX3tW3bVhgzZowgCAXvJz8/P/V9gYGBAgDht99+U0/Lzc0VvL29BSMjIyEtLU0QBEHYtWuXAED4/vvv1fPl5+cLHTt2FAAI69atU0/v1q2b0KJFC43PhUqlEjp06CA0bNhQPe3o0aOleo6ff/65AEBIT0/XmP76668LAITk5OQXv0CCIHh4eAjW1tbC48eP1dMuXbokSKVSYdSoUeppha/lu+++W+zxLC0tNaZ17txZaN68ebHHAiDMmTNH/ffLfj4LNW7cWP0eNDIyEj7//HNBqVS+cDl7e3th8ODBxaYXPtfhw4cXu2/dunUlvvdLuj3LggULBADCvXv3Srz/0aNHgrGxsbBq1SqNxyzPd0MhJycnwdfXV/335MmTBQDCP//8o56Wnp4uuLi4CM7OzurXr/D9WL9+/WLf99nZ2cVe53v37gkKhUL46quvylTfy25L9PX1hfv376unnz17VgAgTJkyRWNZAMVqa9WqleDp6fncenJzcwU3Nzeha9euGtMLt48vuhV97Z/WvHlzoXPnzs+8f9myZYKpqakQHx+vfsySPl+CIAgPHz4UAAjfffddsfvGjh0r6OvrP/NxSsLdai+gUCgwZsyYYtOLjklJT09HYmIiOnbsiKysLI1dGM8ydOhQmJubq//u2LEjgIJ274t0795do93csmVLmJiYqJdVKpU4fPgwBg0apPELxtXVFX369Hnh+kvj/PnziI+Px/jx4zXGU/Tr1w9NmjRRt6gLxwMdO3YMycnJJa6rsMO0Z8+eUv0SeZF9+/YBAAICAjSmf/zxxwBQrH3u4uKCXr16lXr9enp6OHToEA4dOoSDBw9i1apVMDIyQt++fTWOhtq2bRs6duwIc3NzJCYmqm/du3eHUqnE33//DaDg+WdmZuLQoUPler4vMmLECERERODcuXPq/z5rl9q+fftQt25djYHOurq6mDRpEjIyMnD8+HH1fDo6Ohq/OGUyGSZOnKixvqSkJBw5cgRvvfWW+nOSmJiIx48fo1evXrh9+3ax3bAv8vjxY+jo6BT7NZqWlgYApdqF8+jRI1y8eBGjR4+GhYWFenrLli3Ro0cP9XuoqI8++kjj744dO+Lx48fqxy2tivx8rlu3DgcOHMBPP/2Epk2b4smTJy/cHQMUvIZFv3+e9vRzBYBevXqp3/cvupXX9OnTUb9+fbz//vvlXseL7Nu3D+3atdPYXWhkZISxY8ciMjKy2FGnvr6+xcYgKhQK9a4hpVKJx48fw8jICI0bN0ZYWFiZ6nnZbcmgQYNgZ2en/rtdu3bw8vIq9Xv46W1O0XqSk5ORmpqKjh07FnteCxcuLNV74enxjqX1+PFjzJ49G7NmzSpVR7Xw/VzSmCRzc3M8efJEvRu8NLhb7QXs7OxKHOx77do1fP755zhy5EixL8fU1NQXrtfR0VHj78J/2GcFiOctW7h84bLx8fF48uQJXF1di81X0rTyiIqKAoASd0E1adIEJ06cAFDwJfLdd9/h448/ho2NjXrg8qhRo9TjdDp37ozBgwfjyy+/xI8//oguXbpg0KBBGDFiBBQKRblqk0qlxZ5r3bp1YWZmpq69kIuLS5nWL5PJio136du3Lxo2bIiZM2eqBznfvn0bly9ffuYHOz4+HgAwfvx4bN26FX369IGdnR169uyJt956C7179y5TXc/SqlUrNGnSBBs3boSZmRnq1q37zIGJUVFRaNiwYbExAYW7hwpfu6ioKNja2hYLKE+/HyIiIiAIAmbNmoVZs2aV+Jjx8fEaX+7lZWJiAqBgA1PSoOiinvf+bdq0KQ4ePFhsIPLzPrOFj10aFfn59Pb2Vv//sGHD1P9OT4+tKonw7+6ykpT0mbC1tYWtrW2Z6iuLM2fO4Ndff0VwcHClDniOioqCl5dXselF3+NFBwqX9FqoVCosXrwYP/30E+7du6cRSAuHNpTWy25LGjZsWGxao0aNsHXrVo1penp6xb6Lim43Cu3ZswfffPMNLl68qDFG8+mxcJ6eni+s7WV8/vnnsLCwKPaD61kK388ljdl73n3PwnD0AiUdtZSSkoLOnTvDxMQEX331FRo0aAA9PT2EhYVh+vTppTp0XyaTlTj9eV9YFbGsGCZPnowBAwZg165dOHjwIGbNmoX58+fjyJEjaNWqFSQSCYKCgnDmzBn8+eefOHjwIN59910sXLgQZ86cKff+6tJ+EJ53ZFpp2dvbo3HjxupuEFDwBdqjR49n/nJq1KgRgIKBtBcvXsTBgwexf/9+7N+/H+vWrcOoUaNKHAhdHiNGjMCKFStgbGyMoUOHVtnRNoWfhalTpz6zO1fWQGBpaYn8/Hykp6drdImaNGkCoOAw98JObEXS9s+dubk5unbtit9///2F4cjS0vK5P8RK+kw8efKkVBtr4L8DFMpi2rRp6NixI1xcXNQHaxR2AR49eoTo6OgSfxhWtpJei3nz5mHWrFl499138fXXX8PCwgJSqRSTJ08u06lbKmJbUlrPev8W9c8//2DgwIHo1KkTfvrpJ9ja2kJXVxfr1q3Dxo0bNeZNSkoq1Wkx9PX1y3y6iNu3b2P16tUIDAzEw4cP1dOzs7ORl5eHyMhImJiYaHR9C9/PJY13S05OhoGBQZm+6xmOyuHYsWN4/PgxduzYoXG0x71790Ss6j/W1tbQ09NDREREsftKmlYeTk5OAAoGMz/dhbh165b6/kINGjTAxx9/jI8//hi3b9+Gh4cHFi5ciN9++009T/v27dG+fXvMnTsXGzduxMiRI7F58+Yyt9idnJygUqlw+/ZtjQGxcXFxSElJKVZbRcnPz0dGRob67wYNGiAjI6NYl6kkcrkcAwYMwIABA6BSqTB+/HisWrUKs2bNgqur60sfYThixAjMnj0bjx49KnYur6KcnJxw+fJlqFQqjQBV2N4vfO2cnJwQHByMjIwMjfB669YtjfXVr18fQMGuudK8DqVRGILu3buHli1bqqcPGDAA8+fPx2+//fbCcFT0/fu0mzdvwsrK6qUOX3+eyvx8ljbANGnSpMzfV1u2bClxiEFJyhMYo6OjERUVVWKnZuDAgTA1NS3VkXgv4uTk9Mx/98L7XyQoKAivvvoqfvnlF43pKSkpZRqMXhHbktu3bxebFh4eXq6zaW/fvh16eno4ePCgRtd+3bp1xeZ944031LvZn8fX17fMZ8x/8OABVCoVJk2ahEmTJhW738XFBf7+/hpHsBW+ZiUdBHHv3r0yn7OQ4agcChN40S+A3NzcEk9fLobC3T67du3Cw4cP1eMaIiIisH///gp5jDZt2sDa2horV67Eu+++q/4g7d+/Hzdu3FCfhyUrKwtSqVRjXFKDBg1gbGysbtkmJyfDzMxMIwAUXgakPCeA69u3Lz799FMEBgZqHJa/aNEiACjxKK2XFR4ejlu3bmm0mt966y188cUXOHjwYLGuSUpKCoyMjKCjo4PHjx9rtOKlUql6o1/4/As31OXdODRo0ACBgYF48uQJ2rVr98z5+vbti7/++gtbtmxRjzvKz8/H0qVLYWRkhM6dO6vnW716NVasWIFPPvkEQMHYi6VLl2qsz9raGl26dMGqVaswceLEYrtlEhISynyEVuGupPPnz2uEI29vb/Tu3Rs///wz+vTpo750R6Hc3Fx8+umn+OGHH2BrawsPDw9s2LABM2fOVO+Gu3r1Kv76668Xnu/sZVTE5zM+Ph7W1tYa0yIjIxEcHIw2bdq8cHlvb298++23yMnJKfWu68IxR5Vl9erVxcaEHDlyBEuXLsUPP/ygDsUvq2/fvggMDMTp06fV76XMzEysXr0azs7OaNas2QvXIZPJigXAbdu24cGDB2XqhFbEtmTXrl148OCBetd0SEgIzp49i8mTJ5d6HUXrkUgkGrsJIyMjsWvXrmLzLly4sFTDQMpzUlw3N7diRxUDBbva0tPTsXjx4mKneQgNDYVEItHY1VwoLCwMI0eOLFMNDEfl0KFDB5ibm8PX1xeTJk2CRCLBr7/+qjXtdaDgfCV//fUXfHx8MG7cOCiVSixbtgxubm6lPkNtXl5eiSdgs7CwwPjx4/Hdd99hzJgx6Ny5M4YPH64+lN/Z2Vl92YTw8HB069YNb731Fpo1awYdHR3s3LkTcXFxGDZsGABgw4YN+Omnn/D666+jQYMGSE9Px5o1a2BiYoK+ffuW+bm7u7vD19cXq1evVretQ0JCsGHDBgwaNAivvvpqmddZVH5+vrrjpVKpEBkZiZUrV0KlUmHOnDnq+T755BPs3r0b/fv3x+jRo+Hp6YnMzExcuXIFQUFBiIyMhJWVFd5//30kJSWha9eusLe3R1RUFJYuXQoPDw/1rx0PDw/IZDJ89913SE1NhUKhQNeuXYttIJ+n8DD85xk7dixWrVqF0aNHIzQ0FM7OzggKCsLJkycRGBio3o01YMAA+Pj4YMaMGYiMjESzZs2wY8eOErsWy5cvxyuvvIIWLVrggw8+QP369REXF4fTp0/j/v37ZT43TP369eHm5obDhw8XOxfW//73P/Ts2RNvvPEGBgwYgG7dusHQ0BC3b9/G5s2b8ejRI/UupwULFqBPnz7w9vbGe++9pz6U39TUtNKvg/ayn88WLVqgW7du8PDwgLm5OW7fvo1ffvkFeXl5+Pbbb1+4/GuvvYavv/4ax48fR8+ePUtVc3nHHKWmpqpDc+Hh1MuWLYOZmRnMzMzUly8pqY7CHwOdO3fWCH2RkZFwcXEpV1dixowZ2LRpE/r06YNJkybBwsICGzZswL1797B9+/ZS7XLu378/vvrqK4wZMwYdOnTAlStX8Pvvv6s7paVVEdsSV1dXvPLKKxg3bhxycnIQGBgIS0vLcg2E7tevHxYtWoTevXtjxIgRiI+Px/Lly+Hq6orLly9rzFveMUd///23evhBQkICMjMz1duZTp06oVOnTrCysir24waAulNU0n2HDh2Cj49PsTFfoaGhSEpKwmuvvVa2Qst0bFsN9qxD+Z912ODJkyeF9u3bC/r6+kK9evWEadOmCQcPHix2KPKzDr8s6dB2PHW477MO5S966HWhpw9XFQRBCA4OFlq1aiXI5XKhQYMGws8//yx8/PHHgp6e3jNehf8865B1AEKDBg3U823ZskVo1aqVoFAoBAsLC2HkyJEah5UmJiYKfn5+QpMmTQRDQ0PB1NRU8PLyErZu3aqeJywsTBg+fLjg6OgoKBQKwdraWujfv79w/vz5UtVZ0ikH8vLyhC+//FJwcXERdHV1BQcHB2HmzJkah8YWvm79+vV74eM873UxMTERunXrJhw+fLjY/Onp6cLMmTMFV1dXQS6XC1ZWVkKHDh2EH374QcjNzRUEQRCCgoKEnj17CtbW1oJcLhccHR2FDz/8UHj06JHGutasWSPUr19fkMlkLzzkveih/M9T0vspLi5OGDNmjGBlZSXI5XKhRYsWGofmF3r8+LHwzjvvCCYmJoKpqanwzjvvCBcuXCh2KL8gCMKdO3eEUaNGCXXr1hV0dXUFOzs7oX///kJQUJB6ntIeyi8IgrBo0SLByMioxMOgs7KyhB9++EFo27atYGRkJMjlcqFhw4bCxIkTNU6BIQiCcPjwYcHHx0fQ19cXTExMhAEDBgjXr1/XmOdZr2XhYeZFD0sv7aH8gvByn885c+YIbdq0EczNzQUdHR2hXr16wrBhw4TLly+/cNlCLVu2FN57771SPdeXUfidV9Kt6HdjSZ51KP+VK1cEAMKMGTNe+PglfTfeuXNHePPNNwUzMzNBT09PaNeunbBnzx6NeQrfj9u2bSu2zuzsbOHjjz8WbG1tBX19fcHHx0c4ffq00Llz5+ceml6SitiWLFy4UHBwcBAUCoXQsWNH4dKlSxqP8azvyZK2Mb/88ovQsGFDQaFQCE2aNBHWrVtX4nzlVbiukm5Pf0ae9qzPV0pKiiCXy4Wff/652H3Tp08XHB0dBZVKVaY6GY5qmddee03jnDdE1VFKSopgYWFR4pdhdVaVn8///e9/grGxcanPC6VNli9fLhgaGgqxsbFilyKa5/3Qrm1+/PFHwdbWtsTzUdWtW1cIDAws8zp5nqMa7MmTJxp/3759G/v27Sv1VZCJtJWpqSmmTZuGBQsWVOgRPVVJ7M/nyJEj4ejoiOXLl1fJ41Wko0ePYtKkSRpngKbaKS8vD4sWLcLnn39e7Gi0devWQVdXt8Tzdr2IRBC0aKAMVShbW1uMHj0a9evXR1RUFFasWIGcnBxcuHChxHNjEFHV4eezZktISHjuCTnlcrnGoehlVTjuasGCBZg6dWq510Ml44DsGqx3797YtGkTYmNjoVAo4O3tjXnz5vGLl0gL8PNZs7Vt27bYCWeL6ty5c6kuHk3iYOeIiIiogp08ebLYrtOizM3NK/0s01R+ooej5cuXY8GCBYiNjYW7uzuWLl363POwpKSk4LPPPsOOHTuQlJQEJycnBAYGqg/5ViqV+OKLL/Dbb78hNjYW9erVw+jRo/H555+/9In0iIiIqOYTdbfali1bEBAQgJUrV8LLywuBgYHo1asXbt26VeL5W3Jzc9GjRw9YW1sjKCgIdnZ2iIqK0riO0nfffYcVK1Zgw4YNaN68Oc6fP48xY8bA1NS0xDNtEhERERUlaufIy8sLbdu2xbJlywAUnFDPwcEBEydOxIwZM4rNv3LlSixYsAA3b96Erq5uievs378/bGxsNE7rPnjwYOjr62tcquJ5VCoVHj58CGNjY3abiIiIqglBEJCeno569eq93DUkX/L0AuWWk5MjyGQyYefOnRrTR40aJQwcOLDEZfr06SOMHDlS+OCDDwRra2uhefPmwty5c4X8/Hz1PHPnzhWcnJyEW7duCYIgCBcvXhSsra2F3377rdS1xcTEPPMkVbzxxhtvvPHGm3bfYmJiyh5MihBtt1piYiKUSmWx81TY2NioLwD4tLt37+LIkSMYOXIk9u3bh4iICIwfPx55eXnqyzbMmDEDaWlpaNKkCWQyGZRKJebOnfvc66rk5ORoXMNL+LeZFhMTAxMTk5d9qkRERFQF0tLS4ODgoL7UUXlVq0P5VSoVrK2tsXr1ashkMnh6euLBgwdYsGCBOhxt3boVv//+OzZu3IjmzZvj4sWLmDx5MurVqwdfX98S1zt//nx8+eWXxaabmJgwHBEREVUzLzskRrRwZGVlBZlMhri4OI3pcXFxqFu3bonL2NraQldXV30lYwBo2rQpYmNjkZubC7lcjk8++QQzZsxQX9S0RYsWiIqKwvz5858ZjmbOnImAgAD134XJk4iIiGof0S4fIpfL4enpieDgYPU0lUqF4OBgeHt7l7iMj48PIiIiNC4XEB4eDltbW8jlcgBAVlZWsUFYMpnsuZcYUCgU6i4Ru0VERES1m6jXVgsICMCaNWuwYcMG3LhxA+PGjUNmZibGjBkDABg1ahRmzpypnn/cuHFISkqCv78/wsPDsXfvXsybNw9+fn7qeQYMGIC5c+di7969iIyMxM6dO7Fo0SK8/vrrVf78iIiIqPoRdczR0KFDkZCQgNmzZyM2NhYeHh44cOCAepB2dHS0RhfIwcEBBw8exJQpU9CyZUvY2dnB398f06dPV8+zdOlSzJo1C+PHj0d8fDzq1auHDz/8ELNnz67y50dERETVj+hnyNZGaWlpMDU1RWpqKnexERERVRMVtf0WdbcaERERkbZhOCIiIiIqguGIiIiIqAiGIyIiIqIiGI6IiIiIimA4IiIiIiqC4YiIiIioCIajKhYRn46YpCyxyyAiIqJnYDiqQutO3kOPH//G9wdviV0KERERPQPDURXycrGEIAB7Lj9EeFy62OUQERFRCRiOqlCzeibo41YXggAsPnxb7HKIiIioBAxHVcy/e0MAwN4rj3AzNk3kaoiIiOhpDEdVrEldE/RrYQuA3SMiIiJtxHAkAv/uDSGRAPuvxuL6Q3aPiIiItAnDkQga2Rj/1z0KDhe5GiIiIiqK4Ugkk//tHh28FoerD1LFLoeIiIj+xXAkEldrYwx0rwcACOTYIyIiIq3BcCSiSd0aQioBDt+Iw5X77B4RERFpA4YjETWoY4TXPOwAAIGHOfaIiIhIGzAciWxSt4aQSSUIvhmPSzEpYpdDRERU6zEciczFyhCD/u0e/cjuERERkegYjrTApG6ukEklOHYrAWHRyWKXQ0REVKsxHGkBJ0tDvNGqcOwRj1wjIiISE8ORlpjYtSF0pBL8HZ6A0KgkscshIiKqtRiOtISjpQHe9LQHAPx4iN0jIiIisTAcaRG/V12hI5XgREQizkWye0RERCQGhiMt4mBhgCFtHAAAPx7ikWtERERiYDjSMhO6ukJXJsGpO49x9u5jscshIiKqdRiOtIydmT7eKuwe8bxHREREVY7hSAv5veoKuUyKM3eTcOpOotjlEBER1SoMR1qonpk+hrUr6B4FHroNQRBEroiIiKj2YDjSUuO7uEKuI0VIZBJO3eHYIyIioqrCcKSl6prqYUQ7RwAFR66xe0RERFQ1GI602LguDaDQkeJ8VDJORHDsERERUVVgONJiNiZ6GOnlBABYxO4RERFRlWA40nIfdakPPV0pLkSn4Hh4gtjlEBER1XgMR1rO2lgPb//bPfrxMI9cIyIiqmwMR9XAh50bQE9XiksxKTh2i90jIiKiysRwVA3UMVbA19sZQMFZs9k9IiIiqjwMR9XE2E71YSCX4fL9VATfiBe7HCIiohqL4aiasDRSYNS/3aPAYHaPiIiIKgvDUTUytlN9GMpluPogDYeux4ldDhERUY3EcFSNWBjK4dvBGUDBkWsqFbtHREREFY3hqJr5oGN9GCl0cONRGv66Hit2OURERDWO6OFo+fLlcHZ2hp6eHry8vBASEvLc+VNSUuDn5wdbW1soFAo0atQI+/bt05jnwYMHePvtt2FpaQl9fX20aNEC58+fr8ynUWXMDeUY4+MMAAhk94iIiKjCiRqOtmzZgoCAAMyZMwdhYWFwd3dHr169EB9f8tFYubm56NGjByIjIxEUFIRbt25hzZo1sLOzU8+TnJwMHx8f6OrqYv/+/bh+/ToWLlwIc3Pzqnpale79V+rDWKGDm7HpOHCN3SMiIqKKJBFEPOzJy8sLbdu2xbJlywAAKpUKDg4OmDhxImbMmFFs/pUrV2LBggW4efMmdHV1S1znjBkzcPLkSfzzzz/lristLQ2mpqZITU2FiYlJuddTmRYdCseS4NtobGOM/f4dIZVKxC6JiIhIVBW1/Ratc5Sbm4vQ0FB07979v2KkUnTv3h2nT58ucZndu3fD29sbfn5+sLGxgZubG+bNmwelUqkxT5s2bTBkyBBYW1ujVatWWLNmTaU/n6r23isuMNbTwa24dOy7+kjscoiIiGoM0cJRYmIilEolbGxsNKbb2NggNrbkXUV3795FUFAQlEol9u3bh1mzZmHhwoX45ptvNOZZsWIFGjZsiIMHD2LcuHGYNGkSNmzY8MxacnJykJaWpnHTdqb6unj/lfoACsYeKTn2iIiIqEKIPiC7LFQqFaytrbF69Wp4enpi6NCh+Oyzz7By5UqNeVq3bo158+ahVatWGDt2LD744AONeZ42f/58mJqaqm8ODg5V8XRe2phXnGGip4OI+AzsufxQ7HKIiIhqBNHCkZWVFWQyGeLiNE9mGBcXh7p165a4jK2tLRo1agSZTKae1rRpU8TGxiI3N1c9T7NmzTSWa9q0KaKjo59Zy8yZM5Gamqq+xcTElPdpVSkTPV180LGge7QkmN0jIiKiiiBaOJLL5fD09ERwcLB6mkqlQnBwMLy9vUtcxsfHBxEREVCpVOpp4eHhsLW1hVwuV89z69YtjeXCw8Ph5OT0zFoUCgVMTEw0btXFaB9nmBno4k5CJv68xO4RERHRyxJ1t1pAQADWrFmDDRs24MaNGxg3bhwyMzMxZswYAMCoUaMwc+ZM9fzjxo1DUlIS/P39ER4ejr1792LevHnw8/NTzzNlyhScOXMG8+bNQ0REBDZu3IjVq1drzFOTGBfpHi0Ovo18peoFSxAREdHz6Ij54EOHDkVCQgJmz56N2NhYeHh44MCBA+pB2tHR0ZBK/8tvDg4OOHjwIKZMmYKWLVvCzs4O/v7+mD59unqetm3bYufOnZg5cya++uoruLi4IDAwECNHjqzy51dVfDs44+d/7uJeYib+uPgQgz3txS6JiIio2hL1PEfaqjqc5+hpK47dwXcHbsLZ0gCHAzpDR1atxtoTERG9tGp/niOqWKO8nWBhKEfk4yzsvPBA7HKIiIiqLYajGsJQoYMPOxWMPVp6JAJ5HHtERERULgxHNcg73k6wMpIjOikLO8Lui10OERFRtcRwVIMYyHXwUecGAAq6R7n57B4RERGVFcNRDTPSywlWRgrcT36C7eweERERlRnDUQ2jL5dhXJeC7tEydo+IiIjKjOGoBhrp5QhrYwUepDzBttDqcSkUIiIibcFwVAPp6cowvkj3KCdfKXJFRERE1QfDUQ01rJ0j6pro4VFqNraeY/eIiIiotBiOaig9XRnGv1rQPVp+9A6y89g9IiIiKg2GoxpsaFsH2JrqITYtG1vYPSIiIioVhqMaTKEjg9+rrgCA5Ucj2D0iIiIqBYajGu6tNg6wM9NHfHoONp6NFrscIiIircdwVMPJdaTq7tGK4xx7RERE9CIMR7XAm572sDPTR0J6Dn47EyV2OURERFqN4agWkOtIMbFrQfdo5fE7yMrNF7kiIiIi7cVwVEsM9rSHg4U+EjNy2T0iIiJ6DoajWkJXJsXErg0BAKuO32X3iIiI6BkYjmqRN1rZwcnSAI8zc/G/0+weERERlYThqBbR0ege3UFGDrtHRERET2M4qmUGedSDi5UhkrPysOFUpNjlEBERaR2Go1pGRybFpG4FR66t+ecu0rPzRK6IiIhIuzAc1UID3e1Qv44hUtg9IiIiKobhqBaSSSXw71Yw9mjNP/eQxu4RERGRGsNRLdW/ZT24Whsh9Uke1p+MFLscIiIircFwVEtpdo/uIvUJu0dEREQAw1Gt1q+FLRrZGCE9Ox9rT9wTuxwiIiKtwHBUi0mlEvh3awQAWHviHlKz2D0iIiJiOKrl+rjVRZO6xkjPyccvJ+6KXQ4REZHoGI5qOWmRsUdrT0YiJStX5IqIiIjExXBE6NW8LpramiAjJx9r/mH3iIiIajeGI4JUKsHk7gXdo/UnI5GUye4RERHVXgxHBADo2cwGzeuZIDNXye4RERHVagxHBACQSCSY3L3gyLUNpyLxOCNH5IqIiIjEwXBEat2bWqOFnSmycpVY/Te7R0REVDsxHJGaRCLBlB4FY4/+dzoKieweERFRLcRwRBpebWwNdwczPMlTYtXxO2KXQ0REVOUYjkhDwdijgu7Rr2eiEJ+eLXJFREREVYvhiIrp0qgOPBzMkJ2nwqrjHHtERES1C8MRFSORSBDQo+DItd/ORCE+jd0jIiKqPRiOqEQdG1rB08kcOfkq/HSMY4+IiKj2YDiiEkkkEkz597xHG0OiEZvK7hEREdUODEf0TD6ulmjrbI7cfBVWHIsQuxwiIqIqwXBEz1S0e7QpJAaPUp+IXBEREVHlYzii5/JuYAkvFwvkKlVYfpTdIyIiqvm0IhwtX74czs7O0NPTg5eXF0JCQp47f0pKCvz8/GBrawuFQoFGjRph3759Jc777bffFpy7Z/LkSqi85is4a3ZB92jLuRg8SGH3iIiIajbRw9GWLVsQEBCAOXPmICwsDO7u7ujVqxfi4+NLnD83Nxc9evRAZGQkgoKCcOvWLaxZswZ2dnbF5j137hxWrVqFli1bVvbTqNHa17eEd31L5CkFdo+IiKjGEz0cLVq0CB988AHGjBmDZs2aYeXKlTAwMMDatWtLnH/t2rVISkrCrl274OPjA2dnZ3Tu3Bnu7u4a82VkZGDkyJFYs2YNzM3Nq+Kp1GiF3aNt52MQk5QlcjVERESVR9RwlJubi9DQUHTv3l09TSqVonv37jh9+nSJy+zevRve3t7w8/ODjY0N3NzcMG/ePCiVSo35/Pz80K9fP411P0tOTg7S0tI0bqSpnYsFXnG1YveIiIhqPFHDUWJiIpRKJWxsbDSm29jYIDY2tsRl7t69i6CgICiVSuzbtw+zZs3CwoUL8c0336jn2bx5M8LCwjB//vxS1TF//nyYmpqqbw4ODuV/UjXYlB4F11wLCr3P7hEREdVYou9WKyuVSgVra2usXr0anp6eGDp0KD777DOsXLkSABATEwN/f3/8/vvv0NPTK9U6Z86cidTUVPUtJiamMp9CteXpZIGODa2QrxKw9MhtscshIiKqFKKGIysrK8hkMsTFxWlMj4uLQ926dUtcxtbWFo0aNYJMJlNPa9q0KWJjY9W76eLj49G6dWvo6OhAR0cHx48fx5IlS6Cjo1Ns9xsAKBQKmJiYaNyoZIVjj7aHPUDU40yRqyEiIqp4ooYjuVwOT09PBAcHq6epVCoEBwfD29u7xGV8fHwQEREBlUqlnhYeHg5bW1vI5XJ069YNV65cwcWLF9W3Nm3aYOTIkbh48aJGqKKya+1ojs6N6kCpErD0CMceERFRzSP6brWAgACsWbMGGzZswI0bNzBu3DhkZmZizJgxAIBRo0Zh5syZ6vnHjRuHpKQk+Pv7Izw8HHv37sW8efPg5+cHADA2Noabm5vGzdDQEJaWlnBzcxPlOdY0hd2jHWH3cS+R3SMiIqpZdMQuYOjQoUhISMDs2bMRGxsLDw8PHDhwQD1IOzo6GlLpfxnOwcEBBw8exJQpU9CyZUvY2dnB398f06dPF+sp1DoeDmbo2sQaR27GY2nwbSwa6iF2SURERBVGIgiCIHYR2iYtLQ2mpqZITU3l+KNnuHw/BQOXnYRUAhwK6IwGdYzELomIiGq5itp+i75bjaqnlvZm6N7UGioBWBrMI9eIiKjmYDiicpvcvWDs0e5LDxERny5yNURERBWD4YjKzc3OFD2b2UAlAIuDeeQaERHVDAxH9FIKu0d7Lj9EeBy7R0REVP0xHNFLaVbPBL2b14UgAIs59oiIiGoAhiN6af7dC665tu/KI9yM5UV7iYioemM4opfW1NYE/VrYFnSPDrN7RERE1RvDEVUI/+4NIZEA+6/G4vpDdo+IiKj6YjiiCtHIxhj9WtgCABYHh4tcDRERUfkxHFGF8e9W0D06eC0O1x6mil0OERFRuTAcUYVpaGOMAS3rAQACOfaIiIiqKYYjqlCTujUsuN7a9Thcuc/uERERVT8MR1ShXK2N8JqHHQAg8DDHHhERUfXDcEQVbmJXV0glQPDNeFyKSRG7HCIiojJhOKIKV7+OEQa1YveIiIiqJ4YjqhSTujaETCrB0VsJuBCdLHY5REREpcZwRJXC2coQb/zbPfqRR64REVE1wnBElWZi14bQkUrwd3gCQqPYPSIiouqB4YgqjaOlAQa3tgfAsUdERFR9MBxRpZrQ1RU6Ugn+uZ2Ic5FJYpdDRET0QgxHVKkcLAwwpI0DAODHQ+weERGR9mM4oko3oasrdGUSnLrzGGfvPha7HCIioudiOKJKZ2emj7cKu0cce0RERFquzOFow4YN2Lt3r/rvadOmwczMDB06dEBUVFSFFkc1h9+rrpDLpDhzNwmn77B7RERE2qvM4WjevHnQ19cHAJw+fRrLly/H999/DysrK0yZMqXCC6SaoZ6ZPoa2/a97JAiCyBURERGVrMzhKCYmBq6urgCAXbt2YfDgwRg7dizmz5+Pf/75p8ILpJpj/KsNINeRIuReEk6xe0RERFqqzOHIyMgIjx8XbNj++usv9OjRAwCgp6eHJ0+eVGx1VKPYmupjRDtHAAVHrrF7RERE2qjM4ahHjx54//338f777yM8PBx9+/YFAFy7dg3Ozs4VXR/VMOO6NIBCR4rzUck4EZEodjlERETFlDkcLV++HN7e3khISMD27dthaWkJAAgNDcXw4cMrvECqWWxM9DDCi90jIiLSXhKBW6di0tLSYGpqitTUVJiYmIhdTo0Tn56NTt8fRXaeCuvHtEWXxtZil0RERDVARW2/y9w5OnDgAE6cOKH+e/ny5fDw8MCIESOQnMyLi9KLWRvr4W0vJwDAj4dvs3tERERapczh6JNPPkFaWhoA4MqVK/j444/Rt29f3Lt3DwEBARVeINVMH3ZuAD1dKS7FpODYrQSxyyEiIlIrczi6d+8emjVrBgDYvn07+vfvj3nz5mH58uXYv39/hRdINVMdYwVGeTsD4HmPiIhIu5Q5HMnlcmRlZQEADh8+jJ49ewIALCws1B0lotIY26k+9HVluHw/FUduxotdDhEREYByhKNXXnkFAQEB+PrrrxESEoJ+/foBAMLDw2Fvb1/hBVLNZWWkgG8HZwDsHhERkfYoczhatmwZdHR0EBQUhBUrVsDOzg4AsH//fvTu3bvCC6SabWyn+jCUy3D1QRoOXY8TuxwiIiIeyl8SHspftb4/cBM/HbuDZrYm2DvpFUgkErFLIiKiaqiitt865VlIqVRi165duHHjBgCgefPmGDhwIGQyWbkLodrrg4718b/TUbj+KA0Hr8Wht1tdsUsiIqJarMy71SIiItC0aVOMGjUKO3bswI4dO/D222+jefPmuHPnTmXUSDWcuaEco/8dexR4OBwqFZuZREQknjKHo0mTJqFBgwaIiYlBWFgYwsLCEB0dDRcXF0yaNKkyaqRa4P2OLjBW6OBmbDoOXIsVuxwiIqrFyhyOjh8/ju+//x4WFhbqaZaWlvj2229x/PjxCi2Oag8zAznGvOICAFh8+Da7R0REJJoyhyOFQoH09PRi0zMyMiCXyyukKKqd3nvFBcZ6OrgVl459Vx+JXQ4REdVSZQ5H/fv3x9ixY3H27FkIggBBEHDmzBl89NFHGDhwYGXUSLWEqb4u3ivSPVKye0RERCIoczhasmQJGjRoAG9vb+jp6UFPTw8+Pj5wdXVFYGBgJZRItcm7r7jARE8Ht+MzsOfyQ7HLISKiWqjM4cjMzAx//PEHwsPDERQUhKCgINy6dQs7d+6EmZlZuYpYvnw5nJ2doaenBy8vL4SEhDx3/pSUFPj5+cHW1hYKhQKNGjXCvn371PfPnz8fbdu2hbGxMaytrTFo0CDcunWrXLVR1TLR08UHHesDAJYEs3tERERVr8zhqJCrqysGDBiAAQMGwNXVFZcvXy7XmKMtW7YgICAAc+bMQVhYGNzd3dGrVy/Ex5d8ra3c3Fz06NEDkZGR6mC2Zs0a9Zm6gYJB435+fjhz5gwOHTqEvLw89OzZE5mZmeV9ulSFRvs4w8xAF3cSMvHnJXaPiIioalXYGbIvXbqE1q1bQ6lUlmk5Ly8vtG3bFsuWLQMAqFQqODg4YOLEiZgxY0ax+VeuXIkFCxbg5s2b0NXVLdVjJCQkwNraGsePH0enTp1eOD/PkC2+5UcjsODgLdib62O/f0cY65Xu35qIiGqvitp+l7tzVBFyc3MRGhqK7t27q6dJpVJ0794dp0+fLnGZ3bt3w9vbG35+frCxsYGbmxvmzZv33FCWmpoKABqnHygqJycHaWlpGjcSl28HZ9iZ6eN+8hPM2X1N7HKIiKgWETUcJSYmQqlUwsbGRmO6jY0NYmNLPhHg3bt3ERQUBKVSiX379mHWrFlYuHAhvvnmmxLnV6lUmDx5Mnx8fODm5lbiPPPnz4epqan65uDg8HJPjF6akUIHgcM8IJUAO8Ie4I+LD8QuiYiIaolSh6OnOytP30o691FlUKlUsLa2xurVq+Hp6YmhQ4fis88+w8qVK0uc38/PD1evXsXmzZufuc6ZM2ciNTVVfYuJiams8qkM2jpbYGLXhgCAz3deRUxSlsgVERFRbVDqC8+amZk992rpgiCU+WrqVlZWkMlkiIuL05geFxeHunVLvviora0tdHV1NS5y27RpU8TGxiI3N1djUPiECROwZ88e/P3337C3t39mHQqFAgqFoky1U9WY2NUVJyISERqVjMlbLmLL2PbQkYna8CQiohqu1OHo6NGjFf7gcrkcnp6eCA4OxqBBgwAUdIaCg4MxYcKEEpfx8fHBxo0boVKpIJUWbCTDw8Nha2urDkaCIGDixInYuXMnjh07BhcXlwqvnaqGjkyKwKEe6Lv4H4RGJWPpkQhM6dFI7LKIiKgGq7Cj1cpry5Yt8PX1xapVq9CuXTsEBgZi69atuHnzJmxsbDBq1CjY2dlh/vz5AICYmBg0b94cvr6+mDhxIm7fvo13330XkyZNwmeffQYAGD9+PDZu3Ig//vgDjRs3Vj+Wqakp9PX1X1gTj1bTPrsvPcSkTRcglQBbPvRGW+eSB9cTEVHtVVHb71J3jirL0KFDkZCQgNmzZyM2NhYeHh44cOCAepB2dHS0ukMEAA4ODjh48CCmTJmCli1bws7ODv7+/pg+fbp6nhUrVgAAunTpovFY69atw+jRoyv9OVHFG+heD8dvJWB72H1M3nwR+/w7wlSfh/cTEVHFE71zpI3YOdJOGTn56LfkH0Q9zkK/lrZYNrxVmce5ERFRzVUjznNEVBZGCh0sHtYKOlIJ9l5+hKDQ+2KXRERENRDDEVUrHg5mCOhZMCB7zu5ruJfIS8IQEVHFYjiiaufDTg3gXd8SWblK+G++gNx8ldglERFRDVLmAdmvv/56ieM8JBIJ9PT04OrqihEjRmgcJUZUkWRSCRYNdUfvwH9w+X4qFh0Kx4w+TcQui4iIaogyd45MTU1x5MgRhIWFQSKRQCKR4MKFCzhy5Ajy8/OxZcsWuLu74+TJk5VRLxEAwNZUH98NbgEAWPX3HZyMSBS5IiIiqinKHI7q1q2LESNG4O7du9i+fTu2b9+OO3fu4O2330aDBg1w48YN+Pr6ahxaT1QZervZYng7RwgCELD1IpIyc8UuiYiIaoAyH8pfp04dnDx5Eo0aaZ6lODw8HB06dEBiYiKuXLmCjh07IiUlpSJrrTI8lL/6yMrNx4ClJ3AnIRM9mtlg9TuePLyfiKiWEu1Q/vz8fNy8ebPY9Js3b0KpVAIA9PT0uIGiKmEgLzi8Xy6T4tD1OPx+NlrskoiIqJorczh655138N577+HHH3/EiRMncOLECfz444947733MGrUKADA8ePH0bx58wovlqgkbnammNa74ACAr/dcx+24dJErIiKi6qzMu9WUSiW+/fZbLFu2DHFxcQAAGxsbTJw4EdOnT4dMJlNf8sPe3r5Siq5s3K1W/ahUAkavP4e/wxPQ1NYEO8d3gJ6uTOyyiIioClXU9vulLh+SlpYGADUuQDAcVU/x6dnoE/gPHmfm4l0fF8we0EzskoiIqAppxeVDTExMGB5Ia1gb6+GHIe4AgLUn7+HorXiRKyIiouqozOEoLi4O77zzDurVqwcdHR3IZDKNG5GYXm1ijdEdnAEAn2y7hIT0HHELIiKiaqfMZ8gePXo0oqOjMWvWLNja2vKoNNI6M/o0wZm7j3EzNh1Tt13CutFtIZXyfUpERKVT5jFHxsbG+Oeff+Dh4VFJJYmPY46qv/C4dAxYegI5+SrM7t8M777iInZJRERUyUQbc+Tg4ICXGMNNVCUa2Rjj8/4FA7K/3X8T1x+miVwRERFVF2UOR4GBgZgxYwYiIyMroRyiivO2lyO6N7VBrlKFSZsv4EmuUuySiIioGijzbjVzc3NkZWUhPz8fBgYG0NXV1bg/KSmpQgsUA3er1RxJmbnoHfg34tNzMNLLEXNfbyF2SUREVEkqavtd5gHZgYGB5X4woqpmYSjHorc88PYvZ/H72Wh0alQHvZrXFbssIiLSYi91Esiaip2jmmf+vhtY9fddmBno4oB/J9Q11RO7JCIiqmBVOiC78EzYhf//vBuRNvq4Z2O42ZkgJSsPU7ZchFLF3wRERFSyUoUjc3NzxMcXnG3YzMwM5ubmxW6F04m0kVxHiiXDWkFfV4bTdx9j9d93xS6JiIi0VKnGHB05cgQWFhYAgKNHj1ZqQUSVpX4dI3w5sDmmbb+MhX/dQocGlnB3MBO7LCIi0jIcc1QCjjmquQRBwISNF7D3yiM4Wxpg76SOMFSU+bgEIiLSQqIdrQYAKSkpCAkJQXx8PFQqlcZ9o0aNKncxRJVNIpFg3ustcCE6GZGPs/DF7mtY8O/FaomIiIBydI7+/PNPjBw5EhkZGTAxMdG4tppEIuF5jqhaCLmXhGGrT0MlAEuHt8IA93pil0RERC9JtMuHfPzxx3j33XeRkZGBlJQUJCcnq281IRhR7dDOxQITXnUFAHy68wruJ2eJXBEREWmLMoejBw8eYNKkSTAwMKiMeoiqzKRuDdHa0Qzp2fmYvPki8pWqFy9EREQ1XpnDUa9evXD+/PnKqIWoSunIpFg8rBWMFDo4H5WM5UfviF0SERFpgTIPyO7Xrx8++eQTXL9+HS1atCh2bbWBAwdWWHFElc3BwgBzX3eD/+aLWBwcDh9XS7RxthC7LCIiElGZB2RLpc9uNkkkEiiV1f/K5xyQXftM2XIROy88gJ2ZPvZP7ggTPd0XL0RERFpFtAHZKpXqmbeaEIyodvrqteZwsNDHg5Qn+GznVfD0X0REtVeZwxFRTWSsp4vFw1pBJpXgz0sPsSPsgdglERGRSEo15mjJkiUYO3Ys9PT0sGTJkufOO2nSpAopjKiqtXY0x5TuDfHDX+GY/cdVeDqZw9nKUOyyiIioipVqzJGLiwvOnz8PS0tLuLi4PHtlEgnu3q3+F/TkmKPaS6kSMHzNGYTcS4K7vSmCxnWArowNViKi6qCitt+8tloJGI5qt4cpT9A78G+kZedjfJcGmNa7idglERFRKYg2IJuopqtnpo9vB7cEAKw4fgen7iSKXBEREVWlcl149v79+9i9ezeio6ORm5urcd+iRYsqpDAiMfVtYYthbR2w+VwMArZcwn7/jjA3lItdFhERVYEyh6Pg4GAMHDgQ9evXx82bN+Hm5obIyEgIgoDWrVtXRo1Eopg9oBlC7iXhbmImZuy4jJVve2pcaJmIiGqmMu9WmzlzJqZOnYorV65AT08P27dvR0xMDDp37owhQ4ZURo1EojCQ62DJ8FbQlUlw8FocNoXEiF0SERFVgTKHoxs3bmDUqFEAAB0dHTx58gRGRkb46quv8N1331V4gURicrMzxbReBQOyv9pzDRHxGSJXREREla3M4cjQ0FA9zsjW1hZ37vx3sc7ERA5cpZrnvVdc0LGhFbLzVJi06QJy8nkmeCKimqzM4ah9+/Y4ceIEAKBv3774+OOPMXfuXLz77rto3759hRdIJDapVIKFQ9xhYSjH9UdpWHDgltglERFRJSpzOFq0aBG8vLwAAF9++SW6deuGLVu2wNnZGb/88kuFF0ikDaxN9LDgzYLD+38+cQ/HwxNEroiIiCpLmcKRUqnE/fv34ejoCKBgF9vKlStx+fJlbN++HU5OTuUqYvny5XB2doaenh68vLwQEhLy3PlTUlLg5+cHW1tbKBQKNGrUCPv27XupdRK9SLemNhjlXfAe/3jrJSRm5IhcERERVYYyhSOZTIaePXsiOTm5wgrYsmULAgICMGfOHISFhcHd3R29evVCfHx8ifPn5uaiR48eiIyMRFBQEG7duoU1a9bAzs6u3OskKq1P+zZFIxsjJGbk4JNtl8ATzBMR1Txl3q3m5uZWoddPW7RoET744AOMGTMGzZo1w8qVK2FgYIC1a9eWOP/atWuRlJSEXbt2wcfHB87OzujcuTPc3d3LvU6i0tLTlWHJ8FaQ60hx9FYCNpyKFLskIiKqYGUOR9988w2mTp2KPXv24NGjR0hLS9O4lUVubi5CQ0PRvXv3/wqSStG9e3ecPn26xGV2794Nb29v+Pn5wcbGBm5ubpg3bx6USmW515mTk/NSz4NqlyZ1TfBZ36YAgHn7b+LGI75fiIhqklKHo6+++gqZmZno27cvLl26hIEDB8Le3h7m5uYwNzeHmZkZzM3Ny/TgiYmJUCqVsLGx0ZhuY2OD2NjYEpe5e/cugoKCoFQqsW/fPsyaNQsLFy7EN998U+51zp8/H6ampuqbg4NDmZ4H1T6jvJ3QtYk1cvMLDu/PzuPh/URENUWpLx/y5Zdf4qOPPsLRo0crs54XUqlUsLa2xurVqyGTyeDp6YkHDx5gwYIFmDNnTrnWOXPmTAQEBKj/TktLY0Ci55JIJFjwZkv0XvwPbsdnYO7eG/h6kJvYZRERUQUodTgqHHjauXPnCntwKysryGQyxMXFaUyPi4tD3bp1S1zG1tYWurq6kMlk6mlNmzZFbGwscnNzy7VOhUIBhULxks+GahtLIwUWDnHHqLUh+PVMFDo1qoMezWxevCAREWm1Mo05quiLbsrlcnh6eiI4OFg9TaVSITg4GN7e3iUu4+Pjg4iICKhUKvW08PBw2NraQi6Xl2udROXVqVEdfNDRBQAwLegS4tKyRa6IiIheVpnCUaNGjWBhYfHcW1kFBARgzZo12LBhA27cuIFx48YhMzMTY8aMAQCMGjUKM2fOVM8/btw4JCUlwd/fH+Hh4di7dy/mzZsHPz+/Uq+TqCJN7dUYzeuZIDkrDwFbL0Kl4uH9RETVWal3qwEF445MTU0rtIChQ4ciISEBs2fPRmxsLDw8PHDgwAH1gOro6GhIpf9lOAcHBxw8eBBTpkxBy5YtYWdnB39/f0yfPr3U6ySqSAqdgsP7+y85gZMRj7Hmn7v4sHMDscsiIqJykgilPIudVCpFbGwsrK2tK7sm0aWlpcHU1BSpqakwMTERuxyqJjaHRGPGjivQkUqwc7wPWthX7A8JIiJ6vorafpd6t1pFjzciqmmGtnVAH7e6yFcJmLT5AjJz8sUuiYiIyqHU4YiXSSB6PolEgvlvtICtqR7uJWbiqz+vi10SERGVQ6nDUeH5hYjo2cwM5PhxqAckEmDL+RjsvfxI7JKIiKiMynz5ECJ6vvb1LTG+S8GA7Jk7LuNByhORKyIiorJgOCKqBJO7N4K7gxnSsvMxZfNFKHl4PxFRtcFwRFQJdGVSLBnmAUO5DCGRSfjpaITYJRERUSkxHBFVEidLQ/X11gKDbyM0KlnkioiIqDQYjogq0eut7PCaRz0oVQL8N19AWnae2CUREdELMBwRVSKJRIKvB7nB3lwf95OfYPauq2KXREREL8BwRFTJTPR0sXhYK8ikEuy6+BA7L9wXuyQiInoOhiOiKuDpZA7/bg0BALN2XUPU40yRKyIiomdhOCKqIn6vuqKdswUycvLhv/ki8pQqsUsiIqISMBwRVRGZVIIfh3nAWE8HF2NSsPjwbbFLIiKiEjAcEVUhOzN9zH+jBQBg+bEInLn7WOSKiIjoaQxHRFWsf8t6eKuNPQQBmLLlIlKycsUuiYiIimA4IhLBnAHN4WJliEep2Zi54woEgZcXISLSFgxHRCIwVOhg8TAP6Egl2H81FlvPx4hdEhER/YvhiEgkLe3NMLVXYwDAF7uv405ChsgVERERwHBEJKqxHeujQwNLPMlTYtKmC8jJV4pdEhFRrcdwRCQiqVSCRW95wNxAF9cepmHhX+Fil0REVOsxHBGJrK6pHr4b3BIAsPrvu/jndoLIFRER1W4MR0RaoGfzuni7vSMAIGDrJTzOyBG5IiKi2ovhiEhLfNa3GRpaGyEhPQfTgi7z8H4iIpEwHBFpCX25DEuGt4JcR4rgm/H49UyU2CUREdVKDEdEWqSprQlm9mkCAPhm7w3cik0XuSIiotqH4YhIy4zu4IwujesgN1+FSZsuIDuPh/cTEVUlhiMiLSORSPDDEHdYGSlwKy4d8/fdELskIqJaheGISAtZGSnww5CCw/s3nI5C8I04kSsiIqo9GI6ItFSXxtZ47xUXAMAnQZcRn5YtckVERLUDwxGRFpvWuzGa2pogKTMXH2+7BJWKh/cTEVU2hiMiLabQkWHpcA/o6Urxz+1E/HLintglERHVeAxHRFrO1doYs/o3AwB8f/Amrj5IFbkiIqKajeGIqBoY0c4RPZvZIE8pYNLmC8jKzRe7JCKiGovhiKgakEgk+G5wS9iYKHA3IRNf77kudklERDUWwxFRNWFuKMePb3lAIgE2hcRg/5VHYpdERFQjMRwRVSMdXK3wUecGAIAZO67gYcoTkSsiIqp5GI6IqpmAHo3gbm+K1Cd5mLLlIpQ8vJ+IqEIxHBFVM7oyKRYPawUDuQxn7yVh5fE7YpdERFSjMBwRVUPOVob46jU3AMCiQ+G4EJ0sckVERDUHwxFRNTW4tR0GuNeDUiXAf/NFpGfniV0SEVGNwHBEVE1JJBJ8M8gNdmb6iE7Kwmc7r/LyIkREFYDhiKgaM9XXxeJhHpBKgN2XHmLCpjBk5ynFLouIqFpjOCKq5to4W+DHoR7QlUmw70osRqw5g8cZOWKXRURUbTEcEdUAr3nY4df3vGCip4Ow6BS8seIU7iZkiF0WEVG1pBXhaPny5XB2doaenh68vLwQEhLyzHnXr18PiUSicdPT09OYJyMjAxMmTIC9vT309fXRrFkzrFy5srKfBpGo2te3xI7xHWBvro+ox1l4Y8UpnItMErssIqJqR/RwtGXLFgQEBGDOnDkICwuDu7s7evXqhfj4+GcuY2JigkePHqlvUVFRGvcHBATgwIED+O2333Djxg1MnjwZEyZMwO7duyv76RCJytXaGDvH+8DdwQwpWXkYueYs/rz0UOyyiIiqFdHD0aJFi/DBBx9gzJgx6g6PgYEB1q5d+8xlJBIJ6tatq77Z2Nho3H/q1Cn4+vqiS5cucHZ2xtixY+Hu7v7cjhRRTVHHWIHNH7RHj2Y2yFWqMHHTBaw4dgeCwCPZiIhKQ9RwlJubi9DQUHTv3l09TSqVonv37jh9+vQzl8vIyICTkxMcHBzw2muv4dq1axr3d+jQAbt378aDBw8gCAKOHj2K8PBw9OzZs9KeC5E20ZfLsPJtT4zxcQYAfHfgJj7deRX5SpW4hRERVQOihqPExEQolcpinR8bGxvExsaWuEzjxo2xdu1a/PHHH/jtt9+gUqnQoUMH3L9/Xz3P0qVL0axZM9jb20Mul6N3795Yvnw5OnXqVOI6c3JykJaWpnEjqu5kUgnmDGiO2f2bQSIBNoVE470N55GRky92aUREWk303Wpl5e3tjVGjRsHDwwOdO3fGjh07UKdOHaxatUo9z9KlS3HmzBns3r0boaGhWLhwIfz8/HD48OES1zl//nyYmpqqbw4ODlX1dIgq3buvuGDV257Q05XieHgChqw8jdjUbLHLIiLSWhJBxIEIubm5MDAwQFBQEAYNGqSe7uvri5SUFPzxxx+lWs+QIUOgo6ODTZs24cmTJzA1NcXOnTvRr18/9Tzvv/8+7t+/jwMHDhRbPicnBzk5/50XJi0tDQ4ODkhNTYWJiUn5nyCRFrkUk4L3NpxDYkYu6proYd2Ytmhqy/c3EdUcaWlpMDU1fentt6idI7lcDk9PTwQHB6unqVQqBAcHw9vbu1TrUCqVuHLlCmxtbQEAeXl5yMvLg1Sq+dRkMhlUqpLHWygUCpiYmGjciGoadwcz7BzvA1drI8SmZWPIytM4Hp4gdllERFpH9N1qAQEBWLNmDTZs2IAbN25g3LhxyMzMxJgxYwAAo0aNwsyZM9Xzf/XVV/jrr79w9+5dhIWF4e2330ZUVBTef/99AAWH+Xfu3BmffPIJjh07hnv37mH9+vX43//+h9dff12U50ikLRwsDLD9ow5oX98CGTn5eHf9OWwOiRa7LCIiraIjdgFDhw5FQkICZs+ejdjYWHh4eODAgQPqQdrR0dEaXaDk5GR88MEHiI2Nhbm5OTw9PXHq1Ck0a9ZMPc/mzZsxc+ZMjBw5EklJSXBycsLcuXPx0UcfVfnzI9I2pga62PBuO8zYfgU7LzzAjB1XEJOchY97NIZUKhG7PCIi0Yk65khbVdQ+SyJtJggCfjx8G0uCbwMABrrXw4IhLaHQkYlcGRFR+dSIMUdEJB6JRIKAHo2w4M2W0JFKsPvSQ7zzcwiSM3PFLo2ISFQMR0S13JA2Dlg/ph2MFToIiUzC4BWnEPU4U+yyiIhEw3BERHiloRWCxnVAPVM93E3MxOs/nUJYdLLYZRERiYLhiIgAAI3rGmOnnw/c7EyQlJmL4avPYP+VR2KXRURU5RiOiEjNxkQPW8Z6o2sTa+TkqzB+Yxh+/ucuL1pLRLUKwxERaTBU6GD1O554u70jBAH4Zu8NzNl9jRetJaJag+GIiIrRkUnx9Wtu+KxvUwDA/05H4cNfQ5GVy4vWElHNx3BERCWSSCT4oFN9/DSyNRQ6UgTfjMfQVWcQn8aL1hJRzcZwRETP1beFLTZ+0B4WhnJceZCK1386hfC4dLHLIiKqNAxHRPRCnk7m2Dm+A1ysDPEg5QkGrziFUxGJYpdFRFQpGI6IqFScLA2xY1wHtHU2R3p2PkatDUFQ6H2xyyIiqnAMR0RUauaGcvz6nhcGuNdDvkrA1G2X8OOhcB7qT0Q1CsMREZWJnq4Mi4d6YFyXBgCAxcG38fHWS8jN56H+RFQzMBwRUZlJpRJM790E815vAZlUgh0XHsB3bQhSs/LELo2I6KUxHBFRuY3wcsQvvm1gKJfh9N3HGLzyFGKSssQui4jopTAcEdFL6dLYGts+6oC6JnqIiM/A6z+dwuX7KWKXRURUbgxHRPTSmtUzwU6/DmhS1xiJGTkYuuoMDl2PE7ssIqJyYTgiogpha6qPbR95o1OjOniSp8TYX89j/cl7YpdFRFRmDEdEVGGM9XTxi28bDGvrAEEAvvjzOr768zqUKh7qT0TVB8MREVUoXZkU899ogWm9GwMA1p68h/G/h+JJrlLkyoiISofhiIgqnEQiwfgurlgyvBXkMikOXovDsDVnkJiRI3ZpREQvxHBERJVmoHs9/Pa+F8wMdHEpJgWv/3QSEfEZYpdFRPRcDEdEVKnauVhg+7gOcLQwQExSwUVrz959LHZZRETPxHBERJWuQR0j7BzfAa0czZD6JA/v/BKCPy4+ELssIqISMRwRUZWwNFJg0wft0bt5XeQqVfDffBHLjtzmRWuJSOswHBFRldHTleGnka3xQUcXAMAPf4Vj+vbLyFPyorVEpD0YjoioSkmlEnzWrxm+eq05pBJg6/n7eHf9OaRl86K1RKQdGI6ISBSjvJ2xZlQb6OvK8M/tRLy18jQepjwRuywiIoYjIhJPt6Y22PqhN+oYK3AzNh2Dlp/E1QepYpdFRLUcwxERiaqFvSl2ju+ARjZGiE/PwVurTuPozXixyyKiWozhiIhEZ29ugG0fdUCHBpbIylXivQ3n8NuZKLHLIqJaiuGIiLSCqb4u1o9phzc97aESgM93XcX8/Teg4kVriaiKMRwRkdaQ60ix4M2WCOjRCACw6vhdTNx0Adl5vGgtEVUdhiMi0ioSiQSTujXEorfcoSuTYO+VRxj581kkZeaKXRoR1RIMR0Skld5obY8NY9rBWE8HoVHJeOOnk7iXmCl2WURUCzAcEZHW6uBqhR3jOsDOTB+Rj7Pwxk8ncT4ySeyyiKiGYzgiIq3W0MYYO/06oKW9KZKz8jDi57PYc/mh2GURUQ3GcEREWs/aWA+bx7ZH96Y2yM1XYcLGC1h5/A4vWktaIzUrD2fuPkZmTr7YpVAFkAj8dikmLS0NpqamSE1NhYmJidjlENG/lCoBX++5jvWnIgEAI70c8eXA5tCR8XceVT1BEBAWnYKNZ6Ox5/JD5OSrYKTQwWse9TDCyxHN65mKXWKtU1Hbb4ajEjAcEWm3X07cwzd7r0MQgC6N62DZiNYwUuiIXRbVEmnZedh14QE2no3Gzdh09XRjPR2kZ//XOXK3N8UIL0f0b1kPhnx/VgmGo0rEcESk/Q5cjcXkLReQnadCM1sTrB3dFnVN9cQui2ooQRBwMaagS/Tn5YfIzlMBABQ6UvRvWdApauVghjN3H2NjSDQOXotFnrJg82qk0MGgVvUwvB27SZWN4agSMRwRVQ8XopPx/obzeJyZC1tTPawd3RZNbfmZpYqTnp2HXRcfYuPZaNx4lKae3tDaCCO8HPFGK3uYGugWWy4xIwdBofexKSQaUY+z1NPdHcwwop0DBrjXg4Gc3aSKxnBUiRiOiKqP6MdZGL0+BHcTMmGk0MFPI1ujU6M6YpdF1dzl+wVdot2XHiIrt+AM7XIdKfq1sMUIL0e0cTKHRCJ54XpUKgGn/+0m/VWkm2Ss0MGgVnYY3s4RzepxO1NRGI4qEcMRUfWSkpWLD38Nxdl7SdCRSjDv9RZ4q62D2GVRNZORk4/dFx9iY0gUrj74r0vUoI4hRng54Y1WdjA3lJd7/c/qJnk4mGFEO0f0d7dlN+kl1ahwtHz5cixYsACxsbFwd3fH0qVL0a5duxLnXb9+PcaMGaMxTaFQIDs7W2PajRs3MH36dBw/fhz5+flo1qwZtm/fDkdHxxfWw3BEVP3k5CsxLegy/rhYcA6kCa+64uOejUr1655qt6sPUrExJBp/XHiAzMIukUyKPi3qYkQ7R7RzsajQ95G6m3S2YGxSvkqzmzTCy5G7h8uporbfokfULVu2ICAgACtXroSXlxcCAwPRq1cv3Lp1C9bW1iUuY2Jiglu3bqn/fvpNe+fOHbzyyit477338OWXX8LExATXrl2Dnh4HaxLVVAodGQKHesDRwgBLj0Rg2dEIxCRn4fs3W0KhIxO7PNIymTn5+PPSQ2wMicbl+6nq6fWtDDG8nSMGe9rD4iW6RM8jlUrg42oFH1crJKT/102KTsrCr2ei8OuZqIJukpcj+rdkN0kMoneOvLy80LZtWyxbtgwAoFKp4ODggIkTJ2LGjBnF5l+/fj0mT56MlJSUZ65z2LBh0NXVxa+//lqumtg5IqretpyLxqc7r0KpEtDOxQKr3/GEmUHlbOioern+MA0bQ6Kw68JDZPx7wkZdmQS9mtfFCC9HeNe3FKXbqFIJOHXnMTaFFO8mvd66YGwSu0kvViN2q+Xm5sLAwABBQUEYNGiQerqvry9SUlLwxx9/FFtm/fr1eP/992FnZweVSoXWrVtj3rx5aN68OYCCcGVqaopp06bhxIkTuHDhAlxcXDBz5kyNx3gehiOi6u/v8ASM/z0MGTn5qF/HEOtHt4OjpYHYZZEIsnLzsefyI2w8G42LMSnq6c6WBhjezhFvetrD0kghXoFPebqbVKiVoxmGt3PEgJb1oC9nN7QkNSIcPXz4EHZ2djh16hS8vb3V06dNm4bjx4/j7NmzxZY5ffo0bt++jZYtWyI1NRU//PAD/v77b1y7dg329vaIjY2Fra0tDAwM8M033+DVV1/FgQMH8Omnn+Lo0aPo3LlzsXXm5OQgJydH/XdaWhocHBwYjoiquZuxaRiz7hwepWbD0lCOn33boJWjudhlURW5GZuGjWejsfPCA/XJGXWkml0iqVR7x6QVdpM2hkThr2tx/3WT9HTwRis7DPdyRJO63EYVVWvD0dPy8vLQtGlTDB8+HF9//bV6ncOHD8fGjRvV8w0cOBCGhobYtGlTsXV88cUX+PLLL4tNZzgiqv7i0rIxZt05XH+UBoWOFIuHtUJvt7pil0WVJDtP+W+XKAph0Snq6Y4WBhjWzgFDPB1Qx1h7ukSllZCeg22hMdgcElOsmzSiXcFZuNlNqiEDsq2srCCTyRAXF6cxPS4uDnXrlu7LS1dXF61atUJERIR6nTo6OmjWrJnGfE2bNsWJEydKXMfMmTMREBCg/ruwc0RE1Z+NiR62fuSNiRvDcPRWAsb9HoqA7o3wems72Jnp82i2GuJ2XDp+PxuNHWH3kVakS9SjmQ1GeDnCp4GVVneJXqSOsQLju7jio04NcPJOIjaFROOva3G4EJ2CC9Ep+GrPdbzRyg4jvJzQuK6x2OVWe6KGI7lcDk9PTwQHB6vHA6lUKgQHB2PChAmlWodSqcSVK1fQt29f9Trbtm2rcTQbAISHh8PJyanEdSgUCigU1e+XBBGVjpFCB2tGtcGc3dfw+9loLDwUjoWHwlHXRA+eTubwdDJHG2dzNLM14UVsq5HsPCX2XXmETSHROBeZrJ5ub66P4e0cMcTTHtYmNesoZalUgo4N66BjwzqIT89Wj02KSXqCDaejsOF0FFo7mmGElxP6tbBlN6mcRD9abcuWLfD19cWqVavQrl07BAYGYuvWrbh58yZsbGwwatQo2NnZYf78+QCAr776Cu3bt4erqytSUlKwYMEC7Nq1C6Ghoepu0c6dOzF06FAsX75cPeZo8uTJOHbsGF555ZUX1sQB2UQ1kyAI+P1sNLadj8G1h2nqMRyF9HVl8HAwQxvngsDU2skcJnrFLw1B4oqIz8DGs9HYHnYfqU/yAAAyqQTdmlhjhJcjOjWsU627RGWlUgk4eScRG89G49D1/8Ymmejp4I3W9hjezrHWdJNqxJijQsuWLVOfBNLDwwNLliyBl5cXAKBLly5wdnbG+vXrAQBTpkzBjh07EBsbC3Nzc3h6euKbb75Bq1atNNa5du1azJ8/H/fv30fjxo3x5Zdf4rXXXitVPQxHRDVfVm4+LsWkIjQqCeejkhEWlazeHVNIIgEa2xijtZM52jiZo42TBRwsuCtODDn5Shy4Govfz0Yj5F6Seno9Uz0Ma+eIt9o48MLDAOLTs7Ht/H1sPlfQTSrk6WSO4e0Kzpukp1tzu0k1KhxpG4YjotpHpRJwOz4DoVHJOB+VhNCoZI1LPBSqY6xAm393xXk6maN5PVPIdbgrrrLcScjA5pBoBIXeR3JWQZdIKgG6/tsl6tzIGrJa1CUqLZVKwImIgm7S4RvFu0kjvBzRyKbmdZMYjioRwxERAQW/wsOiknE+Mhnno5Jx7WGq+sKhhfR0pWhpb1bQWXI2R2tHc55w8iXl5Ctx8FocNp6Nwpm7/3WJbE31MLStA4a2dYCtqb6IFVYv8WnZ2Pbv2KT7yZrdpBHtHNGvBnWTGI4qEcMREZUkO0+Jy/dTCzpLkckIjU5Gyr/djKIaWhupg1IbZws4WxpwV1wpRCZmYlNINLaF3kdSZi6Agl2brza2xoh2jujSuA4HzL8ElUrAPxGJ2HQ2GoduxEFZA7tJDEeViOGIiEpDpRJwNzED5yOTERpVcLubmFlsPisj+b9ByRyeThZwszPh9d7+lZuvwqHrcdgYEoWTEY/V021MFBjaxgFD2znCzoxdoor2rG5SGydzjPByRN8W1bObxHBUiRiOiKi8HmfkqIPS+ahkXLmfilylSmMeuY4ULe1M4elcMMjb08m80i5yqq2iH2dhY0g0gkJjkJjxX5eoc6M6GN7OEd2aWLNLVAUKu0kbz0bh8I34Yt2kkV6OaFiNukkMR5WI4YiIKkp2nhJXH6Sqw1JoVLJ6l1FR9esYqo+Ia+1kjgZ1DGvcrrg8pQqHr8dhY0g0/rmdqJ5ex/jfLlFbBzhY8Pp3YolLy8a28zHYFBKDByn/dZPaOhcc6VYdukkMR5WI4YiIKosgCLiXmFkQlCILjoy7k1B8V5y5ge6/R8RZoI2zOVrYmWr9hulZYpKysPlcNLaev4+E9P+uY9mxoRVGejmiW1Mb6LJLpDWUKgH/3E7AppBojW6Sqb4u3mhthxHttLebxHBUiRiOiKgqJWfmIiw6WR2YLt1PQU7+U7viZFK42ZmgjbOFevySlRZdSf5p+UoVDt+Ix6aQaPx9OwGFWxorIzmGtHHA8LaOcLRkl0jbxaVlY+u5GGw+V7ybNMLLEX3ctKubxHBUiRiOiEhMufkqXH2Yqu4shUYlq8flFOVsaaDuLLVxMkeDOkainxn6fnIWtpyLwZZzMYgv0iV6xdUKI7wc0b2pDc8LVQ0pVQL+vp2ATWejEXxTs5s0uLU9Rng5wNVa/G4Sw1ElYjgiIm0iCAKik7LU51sKjUpCeFxGsflM9XXR2tEMbZwLBnm725tVybW18pUqHL2VgI1no3As/L8ukaWhHG+2scfwto5wtjKs9DqoasSmFoxNerqb1M7ZAsO9HETtJjEcVSKGIyLSdqlZef/uiivoLF2MSUF2nuauOB2pBM3tTP8d6G0OT2dzWBtX3CU2HqY8UXeJYtOy1dO961tihJcjeja34SkLarDCbtLGs9E4UqSbZGagizdaidNNYjiqRAxHRFTd5ClVuP4wTd1ZOh+ZrLFbq5CDhb769AFtnM3RyNq4TLvilCoBx27FY+PZaBy9FY/Ca/eaG+jiTc+Ci5zWr2NUUU+LqonY1GxsPV8QlDW6SS4WGNHOEb3d6lZJN4nhqBIxHBFRdScIAu4nP1FfK+58ZDJuxaXj6W98Yz2dggHe/14rzsPRDAZynWLri03N/rdLFI2Hqf91ibxcLDDCyxG9mlfNxo+0m1Il4O/wBGwMiUbwjTh1eDYzKBibNLydI1ytKy88MxxVIoYjIqqJ0rLzcCE6BaGRSTj/7664rFylxjwyqQTNbE3UnSU9HRm2nI8pttukKjZ0VL0VdpM2h2gG6nYuFhhZSYGa4agSMRwRUW2Qr1ThZmw6zv8blkKjkvGoyEbsadp6+DZpt8Ju0u9no3Hk5n/dpFaOZtg53qdCH4vhqBIxHBFRbfUg5QnORyapL4HyOCMXvd3q1oiLkpL4HqU+wdZz97HlXDRG+zhjbKcGFbp+hqNKxHBERERUeZQqAXlKldbuVis+6o6IiIioEsmkEsik2rtrlqcpJSIiIiqC4YiIiIioCIYjIiIioiIYjoiIiIiKYDgiIiIiKoLhiIiIiKgIhiMiIiKiIhiOiIiIiIpgOCIiIiIqguGIiIiIqAiGIyIiIqIiGI6IiIiIimA4IiIiIipCR+wCtJEgCACAtLQ0kSshIiKi0ircbhdux8uL4agE6enpAAAHBweRKyEiIqKySk9Ph6mpabmXlwgvG69qIJVKhYcPH8LY2BgSiaRC152WlgYHBwfExMTAxMSkQtdd0/C1Kj2+VqXH16r0+FqVHl+rsqms10sQBKSnp6NevXqQSss/coidoxJIpVLY29tX6mOYmJjwA1RKfK1Kj69V6fG1Kj2+VqXH16psKuP1epmOUSEOyCYiIiIqguGIiIiIqAiGoyqmUCgwZ84cKBQKsUvRenytSo+vVenxtSo9vlalx9eqbLT99eKAbCIiIqIi2DkiIiIiKoLhiIiIiKgIhiMiIiKiIhiOiIiIiIpgOKpCy5cvh7OzM/T09ODl5YWQkBCxS9JKf//9NwYMGIB69epBIpFg165dYpektebPn4+2bdvC2NgY1tbWGDRoEG7duiV2WVppxYoVaNmypfqkc97e3ti/f7/YZVUL3377LSQSCSZPnix2KVrniy++gEQi0bg1adJE7LK01oMHD/D222/D0tIS+vr6aNGiBc6fPy92WcUwHFWRLVu2ICAgAHPmzEFYWBjc3d3Rq1cvxMfHi12a1snMzIS7uzuWL18udila7/jx4/Dz88OZM2dw6NAh5OXloWfPnsjMzBS7NK1jb2+Pb7/9FqGhoTh//jy6du2K1157DdeuXRO7NK127tw5rFq1Ci1bthS7FK3VvHlzPHr0SH07ceKE2CVppeTkZPj4+EBXVxf79+/H9evXsXDhQpibm4tdWjE8lL+KeHl5oW3btli2bBmAguu3OTg4YOLEiZgxY4bI1WkviUSCnTt3YtCgQWKXUi0kJCTA2toax48fR6dOncQuR+tZWFhgwYIFeO+998QuRStlZGSgdevW+Omnn/DNN9/Aw8MDgYGBYpelVb744gvs2rULFy9eFLsUrTdjxgycPHkS//zzj9ilvBA7R1UgNzcXoaGh6N69u3qaVCpF9+7dcfr0aREro5omNTUVQMFGn55NqVRi8+bNyMzMhLe3t9jlaC0/Pz/069dP47uLirt9+zbq1auH+vXrY+TIkYiOjha7JK20e/dutGnTBkOGDIG1tTVatWqFNWvWiF1WiRiOqkBiYiKUSiVsbGw0ptvY2CA2NlakqqimUalUmDx5Mnx8fODm5iZ2OVrpypUrMDIygkKhwEcffYSdO3eiWbNmYpellTZv3oywsDDMnz9f7FK0mpeXF9avX48DBw5gxYoVuHfvHjp27Ij09HSxS9M6d+/exYoVK9CwYUMcPHgQ48aNw6RJk7BhwwaxSytGR+wCiKhi+Pn54erVqxzv8ByNGzfGxYsXkZqaiqCgIPj6+uL48eMMSE+JiYmBv78/Dh06BD09PbHL0Wp9+vRR/3/Lli3h5eUFJycnbN26lbtrn6JSqdCmTRvMmzcPANCqVStcvXoVK1euhK+vr8jVaWLnqApYWVlBJpMhLi5OY3pcXBzq1q0rUlVUk0yYMAF79uzB0aNHYW9vL3Y5Wksul8PV1RWenp6YP38+3N3dsXjxYrHL0jqhoaGIj49H69atoaOjAx0dHRw/fhxLliyBjo4OlEql2CVqLTMzMzRq1AgRERFil6J1bG1ti/0Qadq0qVbuhmQ4qgJyuRyenp4IDg5WT1OpVAgODuZ4B3opgiBgwoQJ2LlzJ44cOQIXFxexS6pWVCoVcnJyxC5D63Tr1g1XrlzBxYsX1bc2bdpg5MiRuHjxImQymdglaq2MjAzcuXMHtra2YpeidXx8fIqdaiQ8PBxOTk4iVfRs3K1WRQICAuDr64s2bdqgXbt2CAwMRGZmJsaMGSN2aVonIyND41fXvXv3cPHiRVhYWMDR0VHEyrSPn58fNm7ciD/++APGxsbqMWympqbQ19cXuTrtMnPmTPTp0weOjo5IT0/Hxo0bcezYMRw8eFDs0rSOsbFxsXFrhoaGsLS05Hi2p0ydOhUDBgyAk5MTHj58iDlz5kAmk2H48OFil6Z1pkyZgg4dOmDevHl46623EBISgtWrV2P16tVil1acQFVm6dKlgqOjoyCXy4V27doJZ86cEbskrXT06FEBQLGbr6+v2KVpnZJeJwDCunXrxC5N67z77ruCk5OTIJfLhTp16gjdunUT/vrrL7HLqjY6d+4s+Pv7i12G1hk6dKhga2sryOVywc7OThg6dKgQEREhdlla688//xTc3NwEhUIhNGnSRFi9erXYJZWI5zkiIiIiKoJjjoiIiIiKYDgiIiIiKoLhiIiIiKgIhiMiIiKiIhiOiIiIiIpgOCIiIiIqguGIiIiIqAiGIyKiZ5BIJNi1a5fYZRBRFWM4IiKtNHr0aEgkkmK33r17i10aEdVwvLYaEWmt3r17Y926dRrTFAqFSNUQUW3BzhERaS2FQoG6detq3MzNzQEU7PJasWIF+vTpA319fdSvXx9BQUEay1+5cgVdu3aFvr4+LC0tMXbsWGRkZGjMs3btWjRv3hwKhQK2traYMGGCxv2JiYl4/fXXYWBggIYNG2L37t3q+5KTkzFy5EjUqVMH+vr6aNiwYbEwR0TVD8MREVVbs2bNwuDBg3Hp0iWMHDkSw4YNw40bNwAAmZmZ6NWrF8zNzXHu3Dls27YNhw8f1gg/K1asgJ+fH8aOHYsrV65g9+7dcHV11XiML7/8Em+99RYuX76Mvn37YuTIkUhKSlI//vXr17F//37cuHEDK1asgJWVVdW9AERUOcS+8i0RUUl8fX0FmUwmGBoaatzmzp0rCIIgABA++ugjjWW8vLyEcePGCYIgCKtXrxbMzc2FjIwM9f179+4VpFKpEBsbKwiCINSrV0/47LPPnlkDAOHzzz9X/52RkSEAEPbv3y8IgiAMGDBAGDNmTMU8YSLSGhxzRERa69VXX8WKFSs0pllYWKj/39vbW+M+b29vXLx4EQBw48YNuLu7w9DQUH2/j48PVCoVbt26BYlEgocPH6Jbt27PraFly5bq/zc0NISJiQni4+MBAOPGjcPgwYMRFhaGnj17YtCgQejQoUO5nisRaQ+GIyLSWoaGhsV2c1UUfX39Us2nq6ur8bdEIoFKpQIA9OnTB1FRUdi3bx8OHTqEbt26wc/PDz/88EOF10tEVYdjjoio2jpz5kyxv5s2bQoAaNq0KS5duoTMzEz1/SdPnoRUKkXjxo1hbGwMZ2dnBAcHv1QNderUga+vL3777TcEBgZi9erVL7U+IhIfO0dEpLVycnIQGxurMU1HR0c96Hnbtm1o06YNXnnlFfz+++8ICQnBL7/8AgAYOXIk5syZA19fX3zxxRdISEjAxIkT8c4778DGxgYA8MUXX+Cjjz6CtbU1+vTpg/T0dJw8eRITJ04sVX2zZ8+Gp6cnmjdvjpycHOzZs0cdzoio+mI4IiKtdeDAAdja2mpMa9y4MW7evAmg4EiyzZs3Y/z48bC1tcWmTZvQrFkzAICBgQEOHjwIf39/tG3bFgYGBhg8eDAWLVqkXpevry+ys7Px448/YurUqbCyssKbb75Z6vrkcjlmzpyJyMhI6Ovro2PHjti8eXMFPHMiEpNEEARB7CKIiMpKIpFg586dGDRokNilEFENwzFHREREREUwHBEREREVwTFHRFQtcUQAEVUWdo6IiIiIimA4IiIiIiqC4YiIiIioCIYjIiIioiIYjoiIiIiKYDgiIiIiKoLhiIiIiKgIhiMiIiKiIhiOiIiIiIr4P2YkJZZTtLvZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.6357\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "# Loading the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# WiCDataset\n",
    "class WiCDataset(Dataset):\n",
    "    def __init__(self, dataset, tokenizer, max_length=128):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.dataset[idx]\n",
    "        sent1, sent2 = sample['sentence1'], sample['sentence2']\n",
    "        start1, end1 = sample['start1'], sample['end1']\n",
    "        start2, end2 = sample['start2'], sample['end2']\n",
    "        label = sample['label']\n",
    "\n",
    "        # Tokenize the sentence\n",
    "        enc1 = self.tokenizer(\n",
    "            sent1,\n",
    "            return_offsets_mapping=True,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        enc2 = self.tokenizer(\n",
    "            sent2,\n",
    "            return_offsets_mapping=True,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        # Extract tokenized input and offsets:\n",
    "        input_ids1 = enc1[\"input_ids\"][0]\n",
    "        attention_mask1 = enc1[\"attention_mask\"][0]\n",
    "        offsets1 = enc1[\"offset_mapping\"][0]\n",
    "        input_ids2 = enc2[\"input_ids\"][0]\n",
    "        attention_mask2 = enc2[\"attention_mask\"][0]\n",
    "        offsets2 = enc2[\"offset_mapping\"][0]\n",
    "\n",
    "        #  # Generate target masks based on start and end indices\n",
    "        target_mask1 = find_target_token_indices(start1, end1, offsets1)\n",
    "        target_mask2 = find_target_token_indices(start2, end2, offsets2)\n",
    "\n",
    "        return {\n",
    "            'input_ids1': input_ids1, 'attention_mask1': attention_mask1,\n",
    "            'input_ids2': input_ids2, 'attention_mask2': attention_mask2,\n",
    "            'target_mask1': target_mask1, 'target_mask2': target_mask2,\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "def find_target_token_indices(start_idx, end_idx, offset_mapping):\n",
    "   \"\"\"\n",
    "    Returns a mask that identifies the tokens corresponding to the target span.\n",
    "    \"\"\"\n",
    "    mask = torch.zeros(offset_mapping.shape[0], dtype=torch.float)\n",
    "    for i, (token_start, token_end) in enumerate(offset_mapping):\n",
    "        token_start = token_start.item()\n",
    "        token_end = token_end.item()\n",
    "        if token_start < end_idx and token_end > start_idx:\n",
    "            mask[i] = 1.0\n",
    "    return mask\n",
    "\n",
    "# WiCClassifier with interaction features\n",
    "class WiCClassifier(nn.Module):\n",
    "    def __init__(self, bert_model):\n",
    "        \"\"\"\n",
    "        Initializes the classifier using BERT model with an additional classification layer.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.bert = bert_model\n",
    "        hidden_size = bert_model.config.hidden_size\n",
    "        combined_size = hidden_size * 4\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(combined_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.4),\n",
    "            nn.Linear(512, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids1, attention_mask1, input_ids2, attention_mask2, target_mask1, target_mask2):\n",
    "       \"\"\"\n",
    "        Forward pass through the BERT model, followed by interaction-based feature extraction.\n",
    "        \"\"\"\n",
    "        output1 = self.bert(input_ids=input_ids1, attention_mask=attention_mask1)\n",
    "        output2 = self.bert(input_ids=input_ids2, attention_mask=attention_mask2)\n",
    "        embeddings1 = output1.last_hidden_state\n",
    "        embeddings2 = output2.last_hidden_state\n",
    "\n",
    "        # Compute target embedding\n",
    "        mask1 = target_mask1.unsqueeze(-1)\n",
    "        mask2 = target_mask2.unsqueeze(-1)\n",
    "        target_embeds1 = embeddings1 * mask1\n",
    "        target_embeds2 = embeddings2 * mask2\n",
    "        sum_embed1 = target_embeds1.sum(dim=1)\n",
    "        sum_embed2 = target_embeds2.sum(dim=1)\n",
    "        count1 = mask1.sum(dim=1).clamp(min=1)\n",
    "        count2 = mask2.sum(dim=1).clamp(min=1)\n",
    "        target_vec1 = sum_embed1 / count1\n",
    "        target_vec2 = sum_embed2 / count2\n",
    "\n",
    "        # Interaction-based features\n",
    "        mult = target_vec1 * target_vec2\n",
    "        abs_diff = torch.abs(target_vec1 - target_vec2)\n",
    "        combined_vec = torch.cat([target_vec1, target_vec2, mult, abs_diff], dim=1)\n",
    "        logits = self.classifier(combined_vec)\n",
    "        return logits\n",
    "\n",
    "# Training configuration\n",
    "num_epochs = 5\n",
    "learning_rate = 2e-5\n",
    "max_length = 128\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device set to use {device}\")\n",
    "\n",
    "# Prepare datasets and dataloaders\n",
    "train_dataset = WiCDataset(dataset['train'], tokenizer, max_length)\n",
    "val_dataset = WiCDataset(dataset['validation'], tokenizer, max_length)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "\n",
    "# Experimenting with different LoRa configurations\n",
    "def get_model_for_lora_config(lora_config):\n",
    "    base_bert = AutoModel.from_pretrained('bert-base-uncased')\n",
    "    bert_model = get_peft_model(base_bert, lora_config)\n",
    "    model = WiCClassifier(bert_model).to(device)\n",
    "    return model\n",
    "\n",
    "# Using 3 different parameters and selecting the best one\n",
    "lora_configs = [\n",
    "    LoraConfig(r=10, lora_alpha=16, target_modules=[\"query\", \"value\"], lora_dropout=0.1, bias=\"none\", task_type=\"FEATURE_EXTRACTION\"),\n",
    "    LoraConfig(r=12, lora_alpha=15, target_modules=[\"query\", \"value\"], lora_dropout=0.1, bias=\"none\", task_type=\"FEATURE_EXTRACTION\"),\n",
    "    LoraConfig(r=14, lora_alpha=14, target_modules=[\"query\", \"value\"], lora_dropout=0.1, bias=\"none\", task_type=\"FEATURE_EXTRACTION\")\n",
    "]\n",
    "\n",
    "best_val_acc = 0\n",
    "best_config = None\n",
    "val_accs = []\n",
    "best_model = None\n",
    "training_losses = []\n",
    "\n",
    "# Training loop for each LoRA configuration\n",
    "for i, lora_config in enumerate(lora_configs):\n",
    "    print(f\"Training with Config {i+1} (r={lora_config.r}, lora_alpha={lora_config.lora_alpha})\")\n",
    "\n",
    "    # Get model for this configuration\n",
    "    model = get_model_for_lora_config(lora_config)\n",
    "\n",
    "    # Setting up optimizer, scheduler, and loss criterion\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
    "    total_steps = len(train_loader) * num_epochs\n",
    "    warmup_steps = int(total_steps * 0.1)\n",
    "    scheduler = LambdaLR(optimizer, lr_lambda=lambda step:\n",
    "        min(1.0, step / warmup_steps) if step < warmup_steps\n",
    "        else max(0.1, 1 - (step - warmup_steps) / (total_steps - warmup_steps))\n",
    "    )\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Training and validation loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        for batch in progress_bar:\n",
    "            input_ids1 = batch['input_ids1'].to(device)\n",
    "            input_ids2 = batch['input_ids2'].to(device)\n",
    "            attention_mask1 = batch['attention_mask1'].to(device)\n",
    "            attention_mask2 = batch['attention_mask2'].to(device)\n",
    "            target_mask1 = batch['target_mask1'].to(device)\n",
    "            target_mask2 = batch['target_mask2'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(input_ids1, attention_mask1, input_ids2, attention_mask2, target_mask1, target_mask2)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} done! Average training loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        correct, total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                input_ids1 = batch['input_ids1'].to(device)\n",
    "                input_ids2 = batch['input_ids2'].to(device)\n",
    "                attention_mask1 = batch['attention_mask1'].to(device)\n",
    "                attention_mask2 = batch['attention_mask2'].to(device)\n",
    "                target_mask1 = batch['target_mask1'].to(device)\n",
    "                target_mask2 = batch['target_mask2'].to(device)\n",
    "                labels = batch['label'].to(device)\n",
    "\n",
    "                outputs = model(input_ids1, attention_mask1, input_ids2, attention_mask2, target_mask1, target_mask2)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_acc = correct / total\n",
    "        val_accs.append(val_acc)\n",
    "        print(f\"Validation accuracy for Config {i+1}: {val_acc:.4f}\")\n",
    "\n",
    "        # Track the best configuration based on validation accuracy\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_config = f\"Config {i+1} (r={lora_config.r}, lora_alpha={lora_config.lora_alpha})\"\n",
    "            best_model = model  # Save the best model\n",
    "\n",
    "        # Track the training loss for the best model\n",
    "        if best_model == model:\n",
    "            training_losses.append(avg_train_loss)\n",
    "\n",
    "# Final results\n",
    "print(f\"Best Validation Accuracy: {best_val_acc:.4f}\")\n",
    "print(f\"Best Configuration: {best_config}\")\n",
    "\n",
    "# Plot training loss for the best model\n",
    "plt.plot(training_losses)\n",
    "plt.title(f\"Training Loss for Best Model ({best_config})\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Training Loss\")\n",
    "plt.show()\n",
    "\n",
    "# Testing  the best model on the test set\n",
    "test_dataset = WiCDataset(dataset['test'], tokenizer, max_length)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "best_model.eval()\n",
    "correct, total = 0, 0\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids1 = batch['input_ids1'].to(device)\n",
    "        input_ids2 = batch['input_ids2'].to(device)\n",
    "        attention_mask1 = batch['attention_mask1'].to(device)\n",
    "        attention_mask2 = batch['attention_mask2'].to(device)\n",
    "        target_mask1 = batch['target_mask1'].to(device)\n",
    "        target_mask2 = batch['target_mask2'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        outputs = best_model(input_ids1, attention_mask1, input_ids2, attention_mask2, target_mask1, target_mask2)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "test_acc = correct / total\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")  # Print test accuracy up to 4 decimals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HWRra63i2oFS"
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BQ6iRsAn2rlE"
   },
   "source": [
    "Congratulations! You finished the assignment & you're ready to submit your work. Please follow the instructions:\n",
    "\n",
    "1. Check and review your answers. Make sure all of the cell outputs are what you want.\n",
    "2. Select File > Save.\n",
    "3. **Fill your information** & run the cell bellow.\n",
    "4. Run **Make Submission** cell, It may take several minutes and it may ask you for your credential.\n",
    "5. Run **Download Submission** cell to obtain your submission as a zip file.\n",
    "6. Grab the downloaded file (`dl_asg01__xx__xx.zip`) and hand it over."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lL9OYI1C1wRq"
   },
   "source": [
    "## Fill your information (Run the cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ra5wTxj62CWc",
    "outputId": "f53af10b-8bbe-428a-b121-2141efea1af6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your student id: C24082638\n",
      "your name: Rehaan Shaikh \n"
     ]
    }
   ],
   "source": [
    "#@title Enter your information & \"RUN the cell!!\" { run: \"auto\" }\n",
    "student_id = \"C24082638\" #@param {type:\"string\"}\n",
    "student_name = \"Rehaan Shaikh \" #@param {type:\"string\"}\n",
    "\n",
    "print(\"your student id:\", student_id)\n",
    "print(\"your name:\", student_name)\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "ASSIGNMENT_PATH = Path('asg01')\n",
    "ASSIGNMENT_PATH.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OFYJJJhh3kpj"
   },
   "source": [
    "## Make Submission (Run the cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cBQc5tBQ2sFJ",
    "outputId": "4ce6b1f6-5422-4ca5-e87a-44d019dbdd59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting templates from packages: 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:pydrive is deprecated and no longer maintained. We recommend that you migrate your projects to pydrive2, the maintained fork of pydrive\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook WiC_Finetuning.ipynb to script\n",
      "[NbConvertApp] Writing 11218 bytes to WiC_Finetuning.txt\n",
      "[NbConvertApp] Converting notebook WiC_Finetuning.ipynb to pdf\n",
      "[NbConvertApp] Writing 72553 bytes to notebook.tex\n",
      "[NbConvertApp] Building PDF\n",
      "[NbConvertApp] Running xelatex 3 times: ['xelatex', 'notebook.tex', '-quiet']\n",
      "[NbConvertApp] Running bibtex 1 time: ['bibtex', 'notebook']\n",
      "[NbConvertApp] WARNING | bibtex had problems, most likely because there were no citations\n",
      "[NbConvertApp] PDF successfully created\n",
      "[NbConvertApp] Writing 83950 bytes to WiC_Finetuning.pdf\n",
      "##########################################\n",
      "Done! Submisson created, Please download using the bellow cell!\n"
     ]
    }
   ],
   "source": [
    "#@title Make submission\n",
    "! pip install -U --quiet PyDrive > /dev/null\n",
    "! pip install -U --quiet jdatetime > /dev/null\n",
    "! apt-get install texlive-xetex texlive-fonts-recommended texlive-plain-generic pandoc > /dev/null\n",
    "\n",
    "import os\n",
    "import time\n",
    "import yaml\n",
    "import json\n",
    "import jdatetime\n",
    "\n",
    "from google.colab import files\n",
    "from IPython.display import Javascript\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "asg_name = 'WiC_Finetuning'\n",
    "script_save = '''\n",
    "require([\"base/js/namespace\"],function(Jupyter) {\n",
    "    Jupyter.notebook.save_checkpoint();\n",
    "});\n",
    "'''\n",
    "\n",
    "submission_file_name = 'dl_asg01__%s__%s.zip'%(student_id, student_name.lower().replace(' ',  '_'))\n",
    "\n",
    "sub_info = {\n",
    "    'student_id': student_id,\n",
    "    'student_name': student_name,\n",
    "    'dateime': str(jdatetime.date.today()),\n",
    "    'asg_name': asg_name\n",
    "}\n",
    "json.dump(sub_info, open('info.json', 'w'))\n",
    "\n",
    "Javascript(script_save)\n",
    "\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)\n",
    "file_id = drive.ListFile({'q':\"title='%s.ipynb'\"%asg_name}).GetList()[0]['id']\n",
    "downloaded = drive.CreateFile({'id': file_id})\n",
    "downloaded.GetContentFile('%s.ipynb'%asg_name)\n",
    "\n",
    "! jupyter nbconvert --to script \"$asg_name\".ipynb > /dev/null\n",
    "! jupyter nbconvert --to pdf \"$asg_name\".ipynb > /dev/null\n",
    "\n",
    "! zip \"$submission_file_name\" \"$asg_name\".ipynb \"$asg_name\".html \"$asg_name\".txt info.json > /dev/null\n",
    "\n",
    "print(\"##########################################\")\n",
    "print(\"Done! Submisson created, Please download using the bellow cell!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "x3n3JS51xqUo",
    "outputId": "0c4df086-1e59-4d20-c091-543f3c6df1ba"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'1gakoqGs5WLPGglk95qmrVIWoNZfIOwvN'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drive.ListFile({'q':\"title='%s.ipynb'\"%asg_name}).GetList()[0]['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "RclPk2VM30Qa",
    "outputId": "76aacf06-2048-4349-d932-757fb9efbd64"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_7318661d-ac0c-4a03-ae67-58cb42d8bb6b\", \"dl_asg01__C24082638__rehaan_shaikh_.zip\", 12657)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "files.download(submission_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m_Qi0HS0xaqL"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
